{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 105\u001b[0m\n\u001b[1;32m    100\u001b[0m transform_steps \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39mimputer\u001b[39m\u001b[39m\"\u001b[39m, SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)),\n\u001b[1;32m    101\u001b[0m                    (\u001b[39m'\u001b[39m\u001b[39mRemoveSkewnessKurtosis\u001b[39m\u001b[39m'\u001b[39m, RemoveSkewnessKurtosis(targets, cat_cols, numeric_cols, log_numeric_cols)),\n\u001b[1;32m    102\u001b[0m                    (\u001b[39m'\u001b[39m\u001b[39mStandardizeStandardScaler\u001b[39m\u001b[39m'\u001b[39m, Standardize(log_numeric_cols, RobustScaler()))]\n\u001b[1;32m    103\u001b[0m transform_pipeline \u001b[39m=\u001b[39m Pipeline(transform_steps)\n\u001b[0;32m--> 105\u001b[0m data_prepared \u001b[39m=\u001b[39m transform_pipeline\u001b[39m.\u001b[39;49mfit_transform(X_train_ad1)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 437\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    439\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/FDA/src/models/transformation.py:119\u001b[0m, in \u001b[0;36mRemoveSkewnessKurtosis.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 119\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_log_col(X)\n",
      "File \u001b[0;32m~/FDA/src/models/transformation.py:110\u001b[0m, in \u001b[0;36mRemoveSkewnessKurtosis.extract_log_col\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_log_col\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 110\u001b[0m   df_log \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremove_skewness(X)\n\u001b[1;32m    111\u001b[0m   log_cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mInternalpatientid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_numeric_cols \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_cols\n\u001b[1;32m    112\u001b[0m   df_log \u001b[39m=\u001b[39m df_log[log_cols]\n",
      "File \u001b[0;32m~/FDA/src/models/transformation.py:98\u001b[0m, in \u001b[0;36mRemoveSkewnessKurtosis.remove_skewness\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_skewness\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> 98\u001b[0m   statusdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_skewness(X)\n\u001b[1;32m     99\u001b[0m   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(statusdf)):\n\u001b[1;32m    100\u001b[0m       \u001b[39mif\u001b[39;00m statusdf[\u001b[39m'\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mYes\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/FDA/src/models/transformation.py:63\u001b[0m, in \u001b[0;36mRemoveSkewnessKurtosis.check_skewness\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     61\u001b[0m method \u001b[39m=\u001b[39m []\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumeric_cols:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(X[i]\u001b[39m.\u001b[39mskew()) \u001b[39m>\u001b[39m \u001b[39m1.96\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mabs\u001b[39m(X[i]\u001b[39m.\u001b[39mkurtosis()) \u001b[39m>\u001b[39m \u001b[39m1.96\u001b[39m:\n\u001b[1;32m     64\u001b[0m         transform\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mYes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m         sknewness_before\u001b[39m.\u001b[39mappend(X[i]\u001b[39m.\u001b[39mskew())\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error,r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import argparse\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "from sklearn.pipeline import  Pipeline, make_pipeline\n",
    "\n",
    "from transformation import RemoveSkewnessKurtosis, Standardize\n",
    "\n",
    "# Import Data\n",
    "# path = '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv'\n",
    "# df1 = pd.read_csv(path).iloc[:,1:]\n",
    "# df1.drop(columns = ['Veteran flag','Event date','Marital status', 'Marital status encoded',\n",
    "#                     'State','Ruca category'], inplace=True, axis=1)\n",
    "# X_admission1 = df1.drop(columns = ['Readmission', 'Died'])\n",
    "# Y_admission1 = df1[['Readmission']]\n",
    "\n",
    "# Split Train and Test\n",
    "# X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 = train_test_split(X_admission1, Y_admission1, test_size=0.20, random_state=42)\n",
    "\n",
    "# 'Internalpatientid' is\n",
    "# Transform Data\n",
    "targets = ['readmission within 300 days', 'died_within_900days']\n",
    "\n",
    "cat_cols = ['AO', 'CVD','Ethnicity', 'Gender', 'Races', 'Ethnicity_0', 'Ethnicity_1', \n",
    "            'Ethnicity_2', 'Races_0', 'Races_1', 'Races_2', 'Races_3', \n",
    "            'Ruca category encoded']\n",
    "\n",
    "cat_cols = ['AO', 'CVD', 'Ruca category encoded', 'Ethnicity', \n",
    "            'Gender', 'Races', 'Ethnicity_0',\n",
    "            'Ethnicity_1', 'Ethnicity_2', 'Races_0', \n",
    "            'Races_1', 'Races_2', 'Races_3','DOMICILIARY', \n",
    "            'MEDICINE', 'NHCU', 'NON-COUNT', 'OTHERS', 'PSYCHIATRY']\n",
    "\n",
    "numeric_cols = ['num_stays', 'stay_length', 'num_unique_units',\n",
    "       'num_transfers', 'num_cvd_readmission', 'unique_admitting_specialty', \n",
    "       'unique_discharging_specialty','Age 20-40', 'Age 40-60', 'Age 60-80', 'Age 80-100',\n",
    "       'Age 100-120', 'age_mean', 'age_std', 'age_min', 'age_max', 'stay_min',\n",
    "       'stay_max', 'stay_mean', 'stay_std', 'freq', 'total_procedure',\n",
    "       'num_surgery_pro', 'num_immunization', 'Num med per admission mean',\n",
    "       'Num med per admission min', 'Num med per admission max',\n",
    "       'Total medications', 'mean age at specailty', 'period mean', \n",
    "       'specialty medical count', 'specialty support count',\n",
    "       'period std','specialty count', 'Age 20-40 hypotension',\n",
    "       'Age 40-60 hypotension', 'Age 60-80 hypotension',\n",
    "       'Age 80-100 hypotension', 'Age 100-120 hypotension',\n",
    "       'Age 20-40 hypertension', 'Age 40-60 hypertension',\n",
    "       'Age 60-80 hypertension', 'Age 80-100 hypertension',\n",
    "       'Age 100-120 hypertension', 'Age 20-40 healthy', 'Age 40-60 healthy',\n",
    "       'Age 60-80 healthy', 'Age 80-100 healthy', 'Age 100-120 healthy',\n",
    "       'lab_count', 'lab_freq', 'lab_age_mean', 'lab_age_std']\n",
    "\n",
    "log_numeric_cols = ['num_stays_log', 'stay_length_log',\n",
    "       'num_transfers_log', 'num_cvd_readmission_log',\n",
    "       'unique_admitting_specialty_log', 'Age 20-40_log', 'Age 40-60_log',\n",
    "       'Age 60-80_log', 'Age 80-100_log', 'Age 100-120_log', 'stay_min_log',\n",
    "       'stay_max_log', 'stay_mean_log', 'stay_std_log', 'freq_log',\n",
    "       'total_procedure_log', 'num_surgery_pro_log',\n",
    "       'Num med per admission mean_log', 'Num med per admission min_log',\n",
    "       'Num med per admission max_log', 'Total medications_log',\n",
    "       'period mean_log', 'specialty medical count_log',\n",
    "       'specialty support count_log', 'period std_log', 'specialty count_log',\n",
    "       'Age 20-40 hypotension_log', 'Age 40-60 hypotension_log',\n",
    "       'Age 60-80 hypotension_log', 'Age 80-100 hypotension_log',\n",
    "       'Age 100-120 hypotension_log', 'Age 20-40 hypertension_log',\n",
    "       'Age 40-60 hypertension_log', 'Age 60-80 hypertension_log',\n",
    "       'Age 80-100 hypertension_log', 'Age 100-120 hypertension_log',\n",
    "       'Age 20-40 healthy_log', 'Age 40-60 healthy_log',\n",
    "       'Age 60-80 healthy_log', 'Age 80-100 healthy_log',\n",
    "       'Age 100-120 healthy_log', 'lab_count_log', 'lab_freq_log']\n",
    "\n",
    "# Import Data\n",
    "path = '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv'\n",
    "df1 = pd.read_csv(path).iloc[:,1:]\n",
    "X_admission1 = df1.drop(columns = ['readmission within 300 days', 'died_within_900days'])\n",
    "Y_admission1 = df1[['readmission within 300 days']]\n",
    "\n",
    "X_mortality1 = df1.drop(columns = ['died_within_900days'])\n",
    "Y_mortality1 = df1[['died_within_900days']]\n",
    "\n",
    "# Split Train and Test\n",
    "X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 = train_test_split(X_admission1, Y_admission1, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "transform_steps = [(\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                   ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis(targets, cat_cols, numeric_cols, log_numeric_cols)),\n",
    "                   ('StandardizeStandardScaler', Standardize(log_numeric_cols, RobustScaler()))]\n",
    "transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "data_prepared = transform_pipeline.fit_transform(X_train_ad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internalpatientid', 'num_stays', 'stay_length', 'num_unique_units',\n",
       "       'num_transfers', 'num_cvd_readmission', 'AO', 'CVD',\n",
       "       'unique_admitting_specialty', 'unique_discharging_specialty',\n",
       "       'DOMICILIARY', 'MEDICINE', 'NHCU', 'NON-COUNT', 'OTHERS', 'PSYCHIATRY',\n",
       "       'SURGERY', 'Age 20-40', 'Age 40-60', 'Age 60-80', 'Age 80-100',\n",
       "       'Age 100-120', 'age_mean', 'age_std', 'age_min', 'age_max', 'stay_min',\n",
       "       'stay_max', 'stay_mean', 'stay_std', 'freq', 'Medical', 'Mental',\n",
       "       'Others_Specialty', 'Rehab', 'Gerontology',\n",
       "       'readmission within 300 days', 'Age at death', 'died_within_900days',\n",
       "       'total_procedure', 'num_surgery_pro', 'Ethnicity', 'Gender', 'Races',\n",
       "       'Ethnicity_0', 'Ethnicity_1', 'Ethnicity_2', 'Races_0', 'Races_1',\n",
       "       'Races_2', 'Races_3', 'num_immunization', 'Num med per admission mean',\n",
       "       'Num med per admission min', 'Num med per admission max',\n",
       "       'Total medications', 'mean age at specailty', 'period mean',\n",
       "       'period std', 'specialty medical count', 'specialty support count',\n",
       "       'specialty count', 'Ruca category encoded', 'Age 20-40 hypotension',\n",
       "       'Age 40-60 hypotension', 'Age 60-80 hypotension',\n",
       "       'Age 80-100 hypotension', 'Age 100-120 hypotension',\n",
       "       'Age 20-40 healthy', 'Age 40-60 healthy', 'Age 60-80 healthy',\n",
       "       'Age 80-100 healthy', 'Age 100-120 healthy', 'Age 20-40 hypertension',\n",
       "       'Age 40-60 hypertension', 'Age 60-80 hypertension',\n",
       "       'Age 80-100 hypertension', 'Age 100-120 hypertension', 'lab_count',\n",
       "       'lab_freq', 'lab_age_mean', 'lab_age_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internalpatientid</th>\n",
       "      <th>num_stays_log_rob_scaled</th>\n",
       "      <th>stay_length_log_rob_scaled</th>\n",
       "      <th>num_transfers_log_rob_scaled</th>\n",
       "      <th>num_cvd_readmission_log_rob_scaled</th>\n",
       "      <th>unique_admitting_specialty_log_rob_scaled</th>\n",
       "      <th>Age 20-40_log_rob_scaled</th>\n",
       "      <th>Age 40-60_log_rob_scaled</th>\n",
       "      <th>Age 60-80_log_rob_scaled</th>\n",
       "      <th>Age 80-100_log_rob_scaled</th>\n",
       "      <th>...</th>\n",
       "      <th>Races_0</th>\n",
       "      <th>Races_1</th>\n",
       "      <th>Races_2</th>\n",
       "      <th>Races_3</th>\n",
       "      <th>DOMICILIARY</th>\n",
       "      <th>MEDICINE</th>\n",
       "      <th>NHCU</th>\n",
       "      <th>NON-COUNT</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>PSYCHIATRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58864</th>\n",
       "      <td>117504</td>\n",
       "      <td>-0.203114</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79350</th>\n",
       "      <td>158601</td>\n",
       "      <td>-0.834044</td>\n",
       "      <td>-1.191133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.226294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16980</th>\n",
       "      <td>33850</td>\n",
       "      <td>-0.834044</td>\n",
       "      <td>0.080737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66650</th>\n",
       "      <td>133029</td>\n",
       "      <td>-0.203114</td>\n",
       "      <td>-0.481701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59734</th>\n",
       "      <td>119286</td>\n",
       "      <td>-0.834044</td>\n",
       "      <td>-0.027878</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.226294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>12293</td>\n",
       "      <td>-0.464974</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.313964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613147</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>109616</td>\n",
       "      <td>1.113928</td>\n",
       "      <td>0.838865</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>1.367211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.773706</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>153543</td>\n",
       "      <td>0.869744</td>\n",
       "      <td>1.182991</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1629</td>\n",
       "      <td>-0.203114</td>\n",
       "      <td>0.440412</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>31484</td>\n",
       "      <td>-0.464974</td>\n",
       "      <td>-0.344871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.313964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613147</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67628 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Internalpatientid  num_stays_log_rob_scaled  \\\n",
       "58864             117504                 -0.203114   \n",
       "79350             158601                 -0.834044   \n",
       "16980              33850                 -0.834044   \n",
       "66650             133029                 -0.203114   \n",
       "59734             119286                 -0.834044   \n",
       "...                  ...                       ...   \n",
       "6265               12293                 -0.464974   \n",
       "54886             109616                  1.113928   \n",
       "76820             153543                  0.869744   \n",
       "860                 1629                 -0.203114   \n",
       "15795              31484                 -0.464974   \n",
       "\n",
       "       stay_length_log_rob_scaled  num_transfers_log_rob_scaled  \\\n",
       "58864                    0.662921                      0.693147   \n",
       "79350                   -1.191133                      0.000000   \n",
       "16980                    0.080737                      0.000000   \n",
       "66650                   -0.481701                      0.000000   \n",
       "59734                   -0.027878                      0.693147   \n",
       "...                           ...                           ...   \n",
       "6265                     0.013631                      0.693147   \n",
       "54886                    0.838865                      1.791759   \n",
       "76820                    1.182991                      0.693147   \n",
       "860                      0.440412                      0.693147   \n",
       "15795                   -0.344871                      0.000000   \n",
       "\n",
       "       num_cvd_readmission_log_rob_scaled  \\\n",
       "58864                            0.000000   \n",
       "79350                            0.000000   \n",
       "16980                            0.000000   \n",
       "66650                            0.000000   \n",
       "59734                            0.000000   \n",
       "...                                   ...   \n",
       "6265                             0.000000   \n",
       "54886                            2.321928   \n",
       "76820                            0.000000   \n",
       "860                              1.000000   \n",
       "15795                            0.000000   \n",
       "\n",
       "       unique_admitting_specialty_log_rob_scaled  Age 20-40_log_rob_scaled  \\\n",
       "58864                                   0.000000                       0.0   \n",
       "79350                                  -0.756471                       0.0   \n",
       "16980                                  -0.756471                       0.0   \n",
       "66650                                   0.000000                       0.0   \n",
       "59734                                  -0.756471                       0.0   \n",
       "...                                          ...                       ...   \n",
       "6265                                   -0.313964                       0.0   \n",
       "54886                                   1.367211                       0.0   \n",
       "76820                                   0.610740                       0.0   \n",
       "860                                     0.000000                       0.0   \n",
       "15795                                  -0.313964                       0.0   \n",
       "\n",
       "       Age 40-60_log_rob_scaled  Age 60-80_log_rob_scaled  \\\n",
       "58864                       0.0                  0.160558   \n",
       "79350                       0.0                 -0.226294   \n",
       "16980                       0.0                 -0.613147   \n",
       "66650                       0.0                  0.000000   \n",
       "59734                       0.0                 -0.226294   \n",
       "...                         ...                       ...   \n",
       "6265                        0.0                 -0.613147   \n",
       "54886                       0.0                  0.773706   \n",
       "76820                       0.0                  0.818378   \n",
       "860                         0.0                  0.160558   \n",
       "15795                       0.0                 -0.613147   \n",
       "\n",
       "       Age 80-100_log_rob_scaled  ...  Races_0  Races_1  Races_2  Races_3  \\\n",
       "58864                   0.000000  ...        1        0        0        0   \n",
       "79350                   0.000000  ...        1        0        0        0   \n",
       "16980                   1.000000  ...        0        1        0        0   \n",
       "66650                   1.000000  ...        0        0        1        0   \n",
       "59734                   0.000000  ...        1        0        0        0   \n",
       "...                          ...  ...      ...      ...      ...      ...   \n",
       "6265                    1.584963  ...        0        1        0        0   \n",
       "54886                   2.584963  ...        0        1        0        0   \n",
       "76820                   0.000000  ...        1        0        0        0   \n",
       "860                     0.000000  ...        0        1        0        0   \n",
       "15795                   1.584963  ...        1        0        0        0   \n",
       "\n",
       "       DOMICILIARY  MEDICINE  NHCU  NON-COUNT  OTHERS  PSYCHIATRY  \n",
       "58864            0         1     0          1       0           1  \n",
       "79350            0         0     0          0       0           0  \n",
       "16980            0         1     0          0       0           0  \n",
       "66650            0         2     0          0       0           0  \n",
       "59734            0         1     0          0       0           0  \n",
       "...            ...       ...   ...        ...     ...         ...  \n",
       "6265             0         0     1          0       0           0  \n",
       "54886            0        13     0          1       2           0  \n",
       "76820            0         9     1          0       0           0  \n",
       "860              0         2     1          0       0           0  \n",
       "15795            0         2     0          0       0           0  \n",
       "\n",
       "[67628 rows x 63 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 210 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n140 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1196, in fit\n    X, y = self._validate_data(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Split Train and Test\u001b[39;00m\n\u001b[1;32m     47\u001b[0m X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 \u001b[39m=\u001b[39m train_test_split(X_admission1, Y_admission1, test_size\u001b[39m=\u001b[39m\u001b[39m0.20\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m LogisticRegression_Grid_CV(X_train_ad1, y_train_ad1, LogisticRegression_param)\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mLogisticRegression_Grid_CV\u001b[0;34m(X_train, y_train, LogisticRegression_param)\u001b[0m\n\u001b[1;32m     32\u001b[0m estimator \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m     33\u001b[0m gsearch \u001b[39m=\u001b[39m GridSearchCV(estimator , param_grid \u001b[39m=\u001b[39m LogisticRegression_param, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m )\n\u001b[0;32m---> 34\u001b[0m gsearch\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     35\u001b[0m gsearch\u001b[39m.\u001b[39mgrid_scores_, gsearch\u001b[39m.\u001b[39mbest_params_, gsearch\u001b[39m.\u001b[39mbest_score_\n\u001b[1;32m     36\u001b[0m print_best_score(gsearch,LogisticRegression_param)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 210 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n140 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1196, in fit\n    X, y = self._validate_data(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import copy,os,sys,psutil\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "def print_best_score(gsearch,param_test):\n",
    "     # 输出best score\n",
    "    print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    # 输出最佳的分类器到底使用了怎样的参数\n",
    "    best_parameters = gsearch.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_test.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    " \n",
    "LogisticRegression_param = { \n",
    "    'penalty' : ['l1','l2'], \n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    }\n",
    "\n",
    "def LogisticRegression_Grid_CV(X_train,y_train, LogisticRegression_param):\n",
    "    estimator = LogisticRegression()\n",
    "    gsearch = GridSearchCV(estimator , param_grid = LogisticRegression_param, scoring='roc_auc', cv=5 )\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "    print_best_score(gsearch,LogisticRegression_param)\n",
    "\n",
    "\n",
    "LogisticRegression_Grid_CV(X_train_ad1, y_train_ad1, LogisticRegression_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internalpatientid', 'num_stays', 'stay_length', 'num_unique_units',\n",
       "       'num_transfers', 'num_cvd_readmission', 'AO', 'CVD',\n",
       "       'unique_admitting_specialty', 'unique_discharging_specialty',\n",
       "       'DOMICILIARY', 'MEDICINE', 'NHCU', 'NON-COUNT', 'OTHERS', 'PSYCHIATRY',\n",
       "       'SURGERY', 'Age 20-40', 'Age 40-60', 'Age 60-80', 'Age 80-100',\n",
       "       'Age 100-120', 'age_mean', 'age_std', 'age_min', 'age_max', 'stay_min',\n",
       "       'stay_max', 'stay_mean', 'stay_std', 'freq', 'Medical', 'Mental',\n",
       "       'Others_Specialty', 'Rehab', 'Gerontology',\n",
       "       'readmission within 300 days', 'Age at death', 'died_within_900days',\n",
       "       'total_procedure', 'num_surgery_pro', 'Ethnicity', 'Gender', 'Races',\n",
       "       'Ethnicity_0', 'Ethnicity_1', 'Ethnicity_2', 'Races_0', 'Races_1',\n",
       "       'Races_2', 'Races_3', 'num_immunization', 'Num med per admission mean',\n",
       "       'Num med per admission min', 'Num med per admission max',\n",
       "       'Total medications', 'mean age at specailty', 'period mean',\n",
       "       'period std', 'specialty medical count', 'specialty support count',\n",
       "       'specialty count', 'Ruca category encoded', 'Age 20-40 hypotension',\n",
       "       'Age 40-60 hypotension', 'Age 60-80 hypotension',\n",
       "       'Age 80-100 hypotension', 'Age 100-120 hypotension',\n",
       "       'Age 20-40 healthy', 'Age 40-60 healthy', 'Age 60-80 healthy',\n",
       "       'Age 80-100 healthy', 'Age 100-120 healthy', 'Age 20-40 hypertension',\n",
       "       'Age 40-60 hypertension', 'Age 60-80 hypertension',\n",
       "       'Age 80-100 hypertension', 'Age 100-120 hypertension', 'lab_count',\n",
       "       'lab_freq', 'lab_age_mean', 'lab_age_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internalpatientid</th>\n",
       "      <th>num_stays</th>\n",
       "      <th>stay_length</th>\n",
       "      <th>num_unique_units</th>\n",
       "      <th>num_transfers</th>\n",
       "      <th>num_cvd_readmission</th>\n",
       "      <th>AO</th>\n",
       "      <th>CVD</th>\n",
       "      <th>unique_admitting_specialty</th>\n",
       "      <th>unique_discharging_specialty</th>\n",
       "      <th>...</th>\n",
       "      <th>Age 100-120 healthy</th>\n",
       "      <th>Age 20-40 hypertension</th>\n",
       "      <th>Age 40-60 hypertension</th>\n",
       "      <th>Age 60-80 hypertension</th>\n",
       "      <th>Age 80-100 hypertension</th>\n",
       "      <th>Age 100-120 hypertension</th>\n",
       "      <th>lab_count</th>\n",
       "      <th>lab_freq</th>\n",
       "      <th>lab_age_mean</th>\n",
       "      <th>lab_age_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>68.340586</td>\n",
       "      <td>3.105130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>71.17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>23.67</td>\n",
       "      <td>64.917227</td>\n",
       "      <td>3.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>78.595827</td>\n",
       "      <td>0.234229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>82.637824</td>\n",
       "      <td>2.862040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>75.673279</td>\n",
       "      <td>0.783771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84531</th>\n",
       "      <td>169055</td>\n",
       "      <td>1</td>\n",
       "      <td>6.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>58.629968</td>\n",
       "      <td>0.503409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84532</th>\n",
       "      <td>169057</td>\n",
       "      <td>28</td>\n",
       "      <td>94.63</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>26.68</td>\n",
       "      <td>80.195538</td>\n",
       "      <td>4.555468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84533</th>\n",
       "      <td>169060</td>\n",
       "      <td>7</td>\n",
       "      <td>41.68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>23.93</td>\n",
       "      <td>62.483905</td>\n",
       "      <td>5.565441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84534</th>\n",
       "      <td>169062</td>\n",
       "      <td>11</td>\n",
       "      <td>135.67</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>72.170051</td>\n",
       "      <td>1.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84535</th>\n",
       "      <td>169064</td>\n",
       "      <td>1</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>79.070914</td>\n",
       "      <td>2.961456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84536 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Internalpatientid  num_stays  stay_length  num_unique_units  \\\n",
       "0                      1          3        14.16                 2   \n",
       "1                      2         21        71.17                 5   \n",
       "2                      3          1         1.83                 1   \n",
       "3                      4          1         7.15                 1   \n",
       "4                      5          1         1.04                 1   \n",
       "...                  ...        ...          ...               ...   \n",
       "84531             169055          1         6.47                 1   \n",
       "84532             169057         28        94.63                 3   \n",
       "84533             169060          7        41.68                 2   \n",
       "84534             169062         11       135.67                 4   \n",
       "84535             169064          1         7.18                 1   \n",
       "\n",
       "       num_transfers  num_cvd_readmission  AO  CVD  \\\n",
       "0                  0                    0   0    0   \n",
       "1                  2                    9   0    1   \n",
       "2                  0                    0   0    1   \n",
       "3                  0                    0   0    1   \n",
       "4                  0                    0   0    1   \n",
       "...              ...                  ...  ..  ...   \n",
       "84531              0                    0   0    1   \n",
       "84532              2                   12   0    1   \n",
       "84533              0                    4   0    1   \n",
       "84534              0                    0   1    0   \n",
       "84535              0                    0   0    0   \n",
       "\n",
       "       unique_admitting_specialty  unique_discharging_specialty  ...  \\\n",
       "0                               3                             2  ...   \n",
       "1                               9                             8  ...   \n",
       "2                               1                             1  ...   \n",
       "3                               1                             1  ...   \n",
       "4                               1                             1  ...   \n",
       "...                           ...                           ...  ...   \n",
       "84531                           1                             1  ...   \n",
       "84532                          11                             9  ...   \n",
       "84533                           5                             2  ...   \n",
       "84534                           6                             4  ...   \n",
       "84535                           1                             1  ...   \n",
       "\n",
       "       Age 100-120 healthy  Age 20-40 hypertension  Age 40-60 hypertension  \\\n",
       "0                      0.0                     0.0                     4.0   \n",
       "1                      0.0                     0.0                    52.0   \n",
       "2                      0.0                     0.0                     0.0   \n",
       "3                      0.0                     0.0                     0.0   \n",
       "4                      0.0                     0.0                     0.0   \n",
       "...                    ...                     ...                     ...   \n",
       "84531                  0.0                     0.0                     3.0   \n",
       "84532                  0.0                     0.0                     0.0   \n",
       "84533                  0.0                     0.0                    43.0   \n",
       "84534                  0.0                     0.0                     0.0   \n",
       "84535                  0.0                     0.0                     0.0   \n",
       "\n",
       "       Age 60-80 hypertension  Age 80-100 hypertension  \\\n",
       "0                       177.0                      0.0   \n",
       "1                       232.0                      0.0   \n",
       "2                         9.0                    178.0   \n",
       "3                         3.0                     38.0   \n",
       "4                        23.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "84531                    25.0                      0.0   \n",
       "84532                   247.0                    218.0   \n",
       "84533                    45.0                      0.0   \n",
       "84534                    84.0                      0.0   \n",
       "84535                    43.0                     49.0   \n",
       "\n",
       "       Age 100-120 hypertension  lab_count  lab_freq  lab_age_mean  \\\n",
       "0                           0.0      159.0     10.60     68.340586   \n",
       "1                           0.0      497.0     23.67     64.917227   \n",
       "2                           0.0       10.0     10.00     78.595827   \n",
       "3                           0.0       98.0      7.00     82.637824   \n",
       "4                           0.0       23.0      7.67     75.673279   \n",
       "...                         ...        ...       ...           ...   \n",
       "84531                       0.0       35.0     17.50     58.629968   \n",
       "84532                       0.0      587.0     26.68     80.195538   \n",
       "84533                       0.0      359.0     23.93     62.483905   \n",
       "84534                       0.0       75.0     18.75     72.170051   \n",
       "84535                       0.0       24.0      2.67     79.070914   \n",
       "\n",
       "       lab_age_std  \n",
       "0         3.105130  \n",
       "1         3.982301  \n",
       "2         0.234229  \n",
       "3         2.862040  \n",
       "4         0.783771  \n",
       "...            ...  \n",
       "84531     0.503409  \n",
       "84532     4.555468  \n",
       "84533     5.565441  \n",
       "84534     1.402000  \n",
       "84535     2.961456  \n",
       "\n",
       "[84536 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classifiers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
