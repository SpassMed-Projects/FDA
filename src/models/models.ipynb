{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv'\n",
    "df1 = pd.read_csv(path).iloc[:,1:]\n",
    "df1.drop(columns = ['Veteran flag','period mean','period std',\n",
    "                    'Event date','Marital status', 'Marital status encoded',\n",
    "                    'State','Ruca category'], inplace=True)\n",
    "\n",
    "\n",
    "path = '/home/daisy/FDA_Dataset/inpatient_all_final_2.csv'\n",
    "df2 = pd.read_csv(path).iloc[:,1:]\n",
    "df2.drop(columns = ['Veteran flag','period mean','period std',\n",
    "                    'Event date','Marital status', 'Marital status encoded',\n",
    "                    'State','Ruca category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84536, 81)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84536 entries, 0 to 84535\n",
      "Data columns (total 81 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Internalpatientid             84536 non-null  int64  \n",
      " 1   num_stays                     84536 non-null  int64  \n",
      " 2   stay_length                   84536 non-null  float64\n",
      " 3   num_unique_units              84536 non-null  int64  \n",
      " 4   num_transfers                 84536 non-null  int64  \n",
      " 5   num_cvd_readmission           84536 non-null  int64  \n",
      " 6   Readmission                   84536 non-null  int64  \n",
      " 7   Died                          84536 non-null  int64  \n",
      " 8   AO                            84536 non-null  int64  \n",
      " 9   CVD                           84536 non-null  int64  \n",
      " 10  unique_admitting_specialty    84536 non-null  int64  \n",
      " 11  unique_discharging_specialty  84536 non-null  int64  \n",
      " 12  DOMICILIARY                   84536 non-null  int64  \n",
      " 13  MEDICINE                      84536 non-null  int64  \n",
      " 14  NHCU                          84536 non-null  int64  \n",
      " 15  NON-COUNT                     84536 non-null  int64  \n",
      " 16  OTHERS                        84536 non-null  int64  \n",
      " 17  PSYCHIATRY                    84536 non-null  int64  \n",
      " 18  SURGERY                       84536 non-null  int64  \n",
      " 19  Age 20-40                     84536 non-null  int64  \n",
      " 20  Age 40-60                     84536 non-null  int64  \n",
      " 21  Age 60-80                     84536 non-null  int64  \n",
      " 22  Age 80-100                    84536 non-null  int64  \n",
      " 23  Age 100-120                   84536 non-null  int64  \n",
      " 24  age_mean                      84536 non-null  float64\n",
      " 25  age_std                       84536 non-null  float64\n",
      " 26  age_min                       84536 non-null  float64\n",
      " 27  age_max                       84536 non-null  float64\n",
      " 28  stay_min                      84536 non-null  float64\n",
      " 29  stay_max                      84536 non-null  float64\n",
      " 30  stay_mean                     84536 non-null  float64\n",
      " 31  stay_std                      84536 non-null  float64\n",
      " 32  freq                          84536 non-null  float64\n",
      " 33  total_procedure               84531 non-null  float64\n",
      " 34  num_surgery_pro               84531 non-null  float64\n",
      " 35  Ethnicity                     84536 non-null  int64  \n",
      " 36  Gender                        84536 non-null  int64  \n",
      " 37  Races                         84536 non-null  int64  \n",
      " 38  Ethnicity_0                   84536 non-null  int64  \n",
      " 39  Ethnicity_1                   84536 non-null  int64  \n",
      " 40  Ethnicity_2                   84536 non-null  int64  \n",
      " 41  Races_0                       84536 non-null  int64  \n",
      " 42  Races_1                       84536 non-null  int64  \n",
      " 43  Races_2                       84536 non-null  int64  \n",
      " 44  Races_3                       84536 non-null  int64  \n",
      " 45  num_immunization              80454 non-null  float64\n",
      " 46  Num med per admission mean    62193 non-null  float64\n",
      " 47  Num med per admission min     62193 non-null  float64\n",
      " 48  Num med per admission max     62193 non-null  float64\n",
      " 49  Total medications             62193 non-null  float64\n",
      " 50  mean age at specailty         84534 non-null  float64\n",
      " 51  period mean                   84534 non-null  object \n",
      " 52  period std                    84534 non-null  object \n",
      " 53  specialty medical count       84534 non-null  float64\n",
      " 54  specialty support count       84534 non-null  float64\n",
      " 55  specialty count               84534 non-null  float64\n",
      " 56  Event date                    84536 non-null  object \n",
      " 57  Marital status                84536 non-null  object \n",
      " 58  Ruca category                 84536 non-null  object \n",
      " 59  Marital status encoded        84191 non-null  float64\n",
      " 60  Ruca category encoded         84536 non-null  float64\n",
      " 61  State                         84536 non-null  object \n",
      " 62  Age 20-40 hypotension         80906 non-null  float64\n",
      " 63  Age 40-60 hypotension         80906 non-null  float64\n",
      " 64  Age 60-80 hypotension         80906 non-null  float64\n",
      " 65  Age 80-100 hypotension        80906 non-null  float64\n",
      " 66  Age 100-120 hypotension       80906 non-null  float64\n",
      " 67  Age 20-40 hypertension        83823 non-null  float64\n",
      " 68  Age 40-60 hypertension        83823 non-null  float64\n",
      " 69  Age 60-80 hypertension        83823 non-null  float64\n",
      " 70  Age 80-100 hypertension       83823 non-null  float64\n",
      " 71  Age 100-120 hypertension      83823 non-null  float64\n",
      " 72  Age 20-40 healthy             83238 non-null  float64\n",
      " 73  Age 40-60 healthy             83238 non-null  float64\n",
      " 74  Age 60-80 healthy             83238 non-null  float64\n",
      " 75  Age 80-100 healthy            83238 non-null  float64\n",
      " 76  Age 100-120 healthy           83238 non-null  float64\n",
      " 77  lab_count                     84503 non-null  float64\n",
      " 78  lab_freq                      84503 non-null  float64\n",
      " 79  lab_age_mean                  84503 non-null  float64\n",
      " 80  lab_age_std                   84503 non-null  float64\n",
      "dtypes: float64(42), int64(33), object(6)\n",
      "memory usage: 52.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84536 entries, 0 to 84535\n",
      "Data columns (total 81 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Internalpatientid             84536 non-null  int64  \n",
      " 1   num_stays                     84536 non-null  int64  \n",
      " 2   stay_length                   84536 non-null  float64\n",
      " 3   num_unique_units              84536 non-null  int64  \n",
      " 4   num_transfers                 84536 non-null  int64  \n",
      " 5   num_cvd_readmission           84536 non-null  int64  \n",
      " 6   Readmission                   84536 non-null  int64  \n",
      " 7   Died                          84536 non-null  int64  \n",
      " 8   AO                            84536 non-null  int64  \n",
      " 9   CVD                           84536 non-null  int64  \n",
      " 10  unique_admitting_specialty    84536 non-null  int64  \n",
      " 11  unique_discharging_specialty  84536 non-null  int64  \n",
      " 12  DOMICILIARY                   84536 non-null  int64  \n",
      " 13  MEDICINE                      84536 non-null  int64  \n",
      " 14  NHCU                          84536 non-null  int64  \n",
      " 15  NON-COUNT                     84536 non-null  int64  \n",
      " 16  OTHERS                        84536 non-null  int64  \n",
      " 17  PSYCHIATRY                    84536 non-null  int64  \n",
      " 18  SURGERY                       84536 non-null  int64  \n",
      " 19  Age 20-40                     84536 non-null  int64  \n",
      " 20  Age 40-60                     84536 non-null  int64  \n",
      " 21  Age 60-80                     84536 non-null  int64  \n",
      " 22  Age 80-100                    84536 non-null  int64  \n",
      " 23  Age 100-120                   84536 non-null  int64  \n",
      " 24  age_mean                      84536 non-null  float64\n",
      " 25  age_std                       84536 non-null  float64\n",
      " 26  age_min                       84536 non-null  float64\n",
      " 27  age_max                       84536 non-null  float64\n",
      " 28  stay_min                      84536 non-null  float64\n",
      " 29  stay_max                      84536 non-null  float64\n",
      " 30  stay_mean                     84536 non-null  float64\n",
      " 31  stay_std                      84536 non-null  float64\n",
      " 32  freq                          84536 non-null  float64\n",
      " 33  total_procedure               84531 non-null  float64\n",
      " 34  num_surgery_pro               84531 non-null  float64\n",
      " 35  Ethnicity                     84536 non-null  int64  \n",
      " 36  Gender                        84536 non-null  int64  \n",
      " 37  Races                         84536 non-null  int64  \n",
      " 38  Ethnicity_0                   84536 non-null  int64  \n",
      " 39  Ethnicity_1                   84536 non-null  int64  \n",
      " 40  Ethnicity_2                   84536 non-null  int64  \n",
      " 41  Races_0                       84536 non-null  int64  \n",
      " 42  Races_1                       84536 non-null  int64  \n",
      " 43  Races_2                       84536 non-null  int64  \n",
      " 44  Races_3                       84536 non-null  int64  \n",
      " 45  num_immunization              80454 non-null  float64\n",
      " 46  Num med per admission mean    62193 non-null  float64\n",
      " 47  Num med per admission min     62193 non-null  float64\n",
      " 48  Num med per admission max     62193 non-null  float64\n",
      " 49  Total medications             62193 non-null  float64\n",
      " 50  mean age at specailty         84534 non-null  float64\n",
      " 51  period mean                   84534 non-null  object \n",
      " 52  period std                    84534 non-null  object \n",
      " 53  specialty medical count       84534 non-null  float64\n",
      " 54  specialty support count       84534 non-null  float64\n",
      " 55  specialty count               84534 non-null  float64\n",
      " 56  Event date                    84536 non-null  object \n",
      " 57  Marital status                84536 non-null  object \n",
      " 58  Ruca category                 84536 non-null  object \n",
      " 59  Marital status encoded        84191 non-null  float64\n",
      " 60  Ruca category encoded         84536 non-null  float64\n",
      " 61  State                         84536 non-null  object \n",
      " 62  Age 20-40 hypotension         80906 non-null  float64\n",
      " 63  Age 40-60 hypotension         80906 non-null  float64\n",
      " 64  Age 60-80 hypotension         80906 non-null  float64\n",
      " 65  Age 80-100 hypotension        80906 non-null  float64\n",
      " 66  Age 100-120 hypotension       80906 non-null  float64\n",
      " 67  Age 20-40 hypertension        83823 non-null  float64\n",
      " 68  Age 40-60 hypertension        83823 non-null  float64\n",
      " 69  Age 60-80 hypertension        83823 non-null  float64\n",
      " 70  Age 80-100 hypertension       83823 non-null  float64\n",
      " 71  Age 100-120 hypertension      83823 non-null  float64\n",
      " 72  Age 20-40 healthy             83238 non-null  float64\n",
      " 73  Age 40-60 healthy             83238 non-null  float64\n",
      " 74  Age 60-80 healthy             83238 non-null  float64\n",
      " 75  Age 80-100 healthy            83238 non-null  float64\n",
      " 76  Age 100-120 healthy           83238 non-null  float64\n",
      " 77  lab_count                     84503 non-null  float64\n",
      " 78  lab_freq                      84503 non-null  float64\n",
      " 79  lab_age_mean                  84503 non-null  float64\n",
      " 80  lab_age_std                   84503 non-null  float64\n",
      "dtypes: float64(42), int64(33), object(6)\n",
      "memory usage: 52.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_admission = df1.drop(columns = ['Readmission'])\n",
    "Y_admission = df1[['Readmission']]\n",
    "\n",
    "X_mortality = df1.drop(columns = ['Died'])\n",
    "Y_mortality = df1[['Died']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ad, X_test_ad, y_train_ad, y_test_ad = train_test_split(X_admission, Y_admission, test_size=0.20, random_state=42)\n",
    "X_train_mor, X_test_mor, y_train_mor, y_test_mor = train_test_split(X_mortality, Y_mortality, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ad[X_train_ad.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m      2\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m lr\u001b[39m.\u001b[39;49mfit(X_train_ad, y_train_ad)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[1;32m      6\u001b[0m lr_prediction \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(X_test_ad)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1197\u001b[0m     X,\n\u001b[1;32m   1198\u001b[0m     y,\n\u001b[1;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1203\u001b[0m )\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# Training\n",
    "lr.fit(X_train_ad, y_train_ad)\n",
    "\n",
    "# Prediction\n",
    "lr_prediction = lr.predict(X_test_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_ad, lr_prediction, target_names= ['Not Readmitted', 'Readmitted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
