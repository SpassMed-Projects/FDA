{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv'\n",
    "df1 = pd.read_csv(path).iloc[:,1:]\n",
    "df1.drop(columns = ['Veteran flag','Event date','Marital status', 'Marital status encoded',\n",
    "                    'State','Ruca category'], inplace=True)\n",
    "\n",
    "\n",
    "path = '/home/daisy/FDA_Dataset/inpatient_all_final_2.csv'\n",
    "df2 = pd.read_csv(path).iloc[:,1:]\n",
    "df2.drop(columns = ['Veteran flag','Event date','Marital status', 'Marital status encoded',\n",
    "                    'State','Ruca category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84536, 81)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84536 entries, 0 to 84535\n",
      "Data columns (total 81 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Internalpatientid             84536 non-null  int64  \n",
      " 1   num_stays                     84536 non-null  int64  \n",
      " 2   stay_length                   84536 non-null  float64\n",
      " 3   num_unique_units              84536 non-null  int64  \n",
      " 4   num_transfers                 84536 non-null  int64  \n",
      " 5   num_cvd_readmission           84536 non-null  int64  \n",
      " 6   Readmission                   84536 non-null  int64  \n",
      " 7   Died                          84536 non-null  int64  \n",
      " 8   AO                            84536 non-null  int64  \n",
      " 9   CVD                           84536 non-null  int64  \n",
      " 10  unique_admitting_specialty    84536 non-null  int64  \n",
      " 11  unique_discharging_specialty  84536 non-null  int64  \n",
      " 12  DOMICILIARY                   84536 non-null  int64  \n",
      " 13  MEDICINE                      84536 non-null  int64  \n",
      " 14  NHCU                          84536 non-null  int64  \n",
      " 15  NON-COUNT                     84536 non-null  int64  \n",
      " 16  OTHERS                        84536 non-null  int64  \n",
      " 17  PSYCHIATRY                    84536 non-null  int64  \n",
      " 18  SURGERY                       84536 non-null  int64  \n",
      " 19  Age 20-40                     84536 non-null  int64  \n",
      " 20  Age 40-60                     84536 non-null  int64  \n",
      " 21  Age 60-80                     84536 non-null  int64  \n",
      " 22  Age 80-100                    84536 non-null  int64  \n",
      " 23  Age 100-120                   84536 non-null  int64  \n",
      " 24  age_mean                      84536 non-null  float64\n",
      " 25  age_std                       84536 non-null  float64\n",
      " 26  age_min                       84536 non-null  float64\n",
      " 27  age_max                       84536 non-null  float64\n",
      " 28  stay_min                      84536 non-null  float64\n",
      " 29  stay_max                      84536 non-null  float64\n",
      " 30  stay_mean                     84536 non-null  float64\n",
      " 31  stay_std                      84536 non-null  float64\n",
      " 32  freq                          84536 non-null  float64\n",
      " 33  total_procedure               84531 non-null  float64\n",
      " 34  num_surgery_pro               84531 non-null  float64\n",
      " 35  Ethnicity                     84536 non-null  int64  \n",
      " 36  Gender                        84536 non-null  int64  \n",
      " 37  Races                         84536 non-null  int64  \n",
      " 38  Ethnicity_0                   84536 non-null  int64  \n",
      " 39  Ethnicity_1                   84536 non-null  int64  \n",
      " 40  Ethnicity_2                   84536 non-null  int64  \n",
      " 41  Races_0                       84536 non-null  int64  \n",
      " 42  Races_1                       84536 non-null  int64  \n",
      " 43  Races_2                       84536 non-null  int64  \n",
      " 44  Races_3                       84536 non-null  int64  \n",
      " 45  num_immunization              80454 non-null  float64\n",
      " 46  Num med per admission mean    62193 non-null  float64\n",
      " 47  Num med per admission min     62193 non-null  float64\n",
      " 48  Num med per admission max     62193 non-null  float64\n",
      " 49  Total medications             62193 non-null  float64\n",
      " 50  mean age at specailty         84534 non-null  float64\n",
      " 51  period mean                   84534 non-null  object \n",
      " 52  period std                    84534 non-null  object \n",
      " 53  specialty medical count       84534 non-null  float64\n",
      " 54  specialty support count       84534 non-null  float64\n",
      " 55  specialty count               84534 non-null  float64\n",
      " 56  Event date                    84536 non-null  object \n",
      " 57  Marital status                84536 non-null  object \n",
      " 58  Ruca category                 84536 non-null  object \n",
      " 59  Marital status encoded        84191 non-null  float64\n",
      " 60  Ruca category encoded         84536 non-null  float64\n",
      " 61  State                         84536 non-null  object \n",
      " 62  Age 20-40 hypotension         80906 non-null  float64\n",
      " 63  Age 40-60 hypotension         80906 non-null  float64\n",
      " 64  Age 60-80 hypotension         80906 non-null  float64\n",
      " 65  Age 80-100 hypotension        80906 non-null  float64\n",
      " 66  Age 100-120 hypotension       80906 non-null  float64\n",
      " 67  Age 20-40 hypertension        83823 non-null  float64\n",
      " 68  Age 40-60 hypertension        83823 non-null  float64\n",
      " 69  Age 60-80 hypertension        83823 non-null  float64\n",
      " 70  Age 80-100 hypertension       83823 non-null  float64\n",
      " 71  Age 100-120 hypertension      83823 non-null  float64\n",
      " 72  Age 20-40 healthy             83238 non-null  float64\n",
      " 73  Age 40-60 healthy             83238 non-null  float64\n",
      " 74  Age 60-80 healthy             83238 non-null  float64\n",
      " 75  Age 80-100 healthy            83238 non-null  float64\n",
      " 76  Age 100-120 healthy           83238 non-null  float64\n",
      " 77  lab_count                     84503 non-null  float64\n",
      " 78  lab_freq                      84503 non-null  float64\n",
      " 79  lab_age_mean                  84503 non-null  float64\n",
      " 80  lab_age_std                   84503 non-null  float64\n",
      "dtypes: float64(42), int64(33), object(6)\n",
      "memory usage: 52.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_admission = df1.drop(columns = ['Readmission','Died'])\n",
    "Y_admission = df1[['Readmission']]\n",
    "\n",
    "X_mortality = df1.drop(columns = ['Died'])\n",
    "Y_mortality = df1[['Died']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ad, X_test_ad, y_train_ad, y_test_ad = train_test_split(X_admission, Y_admission, test_size=0.20, random_state=42)\n",
    "X_train_mor, X_test_mor, y_train_mor, y_test_mor = train_test_split(X_mortality, Y_mortality, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_procedure',\n",
       " 'num_surgery_pro',\n",
       " 'num_immunization',\n",
       " 'Num med per admission mean',\n",
       " 'Num med per admission min',\n",
       " 'Num med per admission max',\n",
       " 'Total medications',\n",
       " 'mean age at specailty',\n",
       " 'period mean',\n",
       " 'period std',\n",
       " 'specialty medical count',\n",
       " 'specialty support count',\n",
       " 'specialty count',\n",
       " 'Age 20-40 hypotension',\n",
       " 'Age 40-60 hypotension',\n",
       " 'Age 60-80 hypotension',\n",
       " 'Age 80-100 hypotension',\n",
       " 'Age 100-120 hypotension',\n",
       " 'Age 20-40 hypertension',\n",
       " 'Age 40-60 hypertension',\n",
       " 'Age 60-80 hypertension',\n",
       " 'Age 80-100 hypertension',\n",
       " 'Age 100-120 hypertension',\n",
       " 'Age 20-40 healthy',\n",
       " 'Age 40-60 healthy',\n",
       " 'Age 60-80 healthy',\n",
       " 'Age 80-100 healthy',\n",
       " 'Age 100-120 healthy',\n",
       " 'lab_count',\n",
       " 'lab_freq',\n",
       " 'lab_age_mean',\n",
       " 'lab_age_std']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns[df1.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling continuous features with mean values\n",
    "numeric_cols = df1.columns[df1.isna().any()].tolist()\n",
    "\n",
    "X_train_ad[numeric_cols] = X_train_ad[numeric_cols].fillna(X_train_ad[numeric_cols].mean())\n",
    "X_train_mor[numeric_cols] =  X_train_mor[numeric_cols].fillna(X_train_mor[numeric_cols].mean())\n",
    "\n",
    "X_test_ad[numeric_cols] = X_test_ad[numeric_cols].fillna(X_test_ad[numeric_cols].mean())\n",
    "X_test_mor[numeric_cols] = X_test_mor[numeric_cols].fillna(X_test_mor[numeric_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ad.isna().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr =LogisticRegression()\n",
    "# Training\n",
    "lr.fit(X_train_ad, y_train_ad)\n",
    "\n",
    "# Prediction\n",
    "lr_prediction = lr.predict(X_test_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not Readmitted       0.87      0.85      0.86      3316\n",
      "    Readmitted       0.96      0.97      0.97     13592\n",
      "\n",
      "      accuracy                           0.95     16908\n",
      "     macro avg       0.92      0.91      0.91     16908\n",
      "  weighted avg       0.94      0.95      0.94     16908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ad, lr_prediction, target_names= ['Not Readmitted', 'Readmitted']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# Training\n",
    "lr.fit(X_train_mor, y_train_mor)\n",
    "\n",
    "# Prediction\n",
    "lr_prediction = lr.predict(X_test_mor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Died       0.83      0.99      0.90     13744\n",
      "        Died       0.65      0.11      0.19      3164\n",
      "\n",
      "    accuracy                           0.82     16908\n",
      "   macro avg       0.74      0.55      0.55     16908\n",
      "weighted avg       0.79      0.82      0.77     16908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_mor, lr_prediction, target_names= ['Not Died', 'Died']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.371450\n",
      "         Iterations 11\n",
      "                                       Results: Logit\n",
      "============================================================================================\n",
      "Model:                       Logit                     Pseudo R-squared:          0.224     \n",
      "Dependent Variable:          Died                      AIC:                       50378.8745\n",
      "Date:                        2023-07-18 15:45          BIC:                       51008.2771\n",
      "No. Observations:            67628                     Log-Likelihood:            -25120.   \n",
      "Df Model:                    68                        LL-Null:                   -32361.   \n",
      "Df Residuals:                67559                     LLR p-value:               0.0000    \n",
      "Converged:                   1.0000                    Scale:                     1.0000    \n",
      "No. Iterations:              11.0000                                                        \n",
      "--------------------------------------------------------------------------------------------\n",
      "                              Coef.    Std.Err.      z     P>|z|      [0.025       0.975]   \n",
      "--------------------------------------------------------------------------------------------\n",
      "Internalpatientid            -0.0000       0.0000  -0.4468 0.6550       -0.0000       0.0000\n",
      "num_stays                    -0.0697  255746.9859  -0.0000 1.0000  -501254.9513  501254.8118\n",
      "stay_length                  -0.0003       0.0002  -1.7149 0.0864       -0.0007       0.0000\n",
      "num_unique_units              0.0826       0.0197   4.1977 0.0000        0.0440       0.1211\n",
      "num_transfers                 0.0331       0.0152   2.1829 0.0290        0.0034       0.0628\n",
      "num_cvd_readmission          -0.0144       0.0058  -2.4633 0.0138       -0.0258      -0.0029\n",
      "Readmission                   0.1894       0.0445   4.2524 0.0000        0.1021       0.2768\n",
      "AO                            0.0527       0.0284   1.8540 0.0637       -0.0030       0.1085\n",
      "CVD                          -0.1622       0.0256  -6.3282 0.0000       -0.2124      -0.1120\n",
      "unique_admitting_specialty   -0.0055       0.0101  -0.5429 0.5872       -0.0254       0.0144\n",
      "unique_discharging_specialty  0.2862       0.0136  21.0601 0.0000        0.2595       0.3128\n",
      "DOMICILIARY                  -0.1545  342688.0867  -0.0000 1.0000  -671656.4623  671656.1534\n",
      "MEDICINE                      0.0626  343948.6764   0.0000 1.0000  -674126.9556  674127.0808\n",
      "NHCU                          0.2135  339719.5349   0.0000 1.0000  -665837.8398  665838.2668\n",
      "NON-COUNT                    -0.1053  337913.2626  -0.0000 1.0000  -662297.9299  662297.7193\n",
      "OTHERS                        0.0250  340704.2428   0.0000 1.0000  -667768.0202  667768.0702\n",
      "PSYCHIATRY                   -0.0346  371174.1509  -0.0000 1.0000  -727488.0024  727487.9331\n",
      "SURGERY                      -0.0766  359851.7234  -0.0000 1.0000  -705296.4942  705296.3410\n",
      "Age 20-40                     0.0607          nan      nan    nan           nan          nan\n",
      "Age 40-60                     0.0326          nan      nan    nan           nan          nan\n",
      "Age 60-80                     0.0129          nan      nan    nan           nan          nan\n",
      "Age 80-100                    0.0128          nan      nan    nan           nan          nan\n",
      "Age 100-120                  -0.1891          nan      nan    nan           nan          nan\n",
      "age_mean                     -0.2019       0.0303  -6.6667 0.0000       -0.2612      -0.1425\n",
      "age_std                       0.1855       0.0214   8.6762 0.0000        0.1436       0.2274\n",
      "age_min                      -0.0409       0.0096  -4.2428 0.0000       -0.0599      -0.0220\n",
      "age_max                      -0.0606       0.0154  -3.9393 0.0001       -0.0907      -0.0304\n",
      "stay_min                      0.0025          nan      nan    nan           nan          nan\n",
      "stay_max                      0.0025          nan      nan    nan           nan          nan\n",
      "stay_mean                    -0.0013       0.0016  -0.8116 0.4170       -0.0045       0.0019\n",
      "stay_std                      0.0043       0.0011   3.8857 0.0001        0.0021       0.0064\n",
      "freq                          0.0602       0.0124   4.8442 0.0000        0.0358       0.0845\n",
      "total_procedure              -0.0000       0.0000  -2.3648 0.0180       -0.0001      -0.0000\n",
      "num_surgery_pro              -0.0051       0.0013  -4.0277 0.0001       -0.0075      -0.0026\n",
      "Ethnicity                    -1.1164  431031.2660  -0.0000 1.0000  -844806.8740  844804.6413\n",
      "Gender                        0.3406       0.0805   4.2323 0.0000        0.1829       0.4984\n",
      "Races                        -0.6912          nan      nan    nan           nan          nan\n",
      "Ethnicity_0                  -1.9584 3633658.4313  -0.0000 1.0000 -7121841.6158 7121837.6990\n",
      "Ethnicity_1                  -1.2347 3014596.8752  -0.0000 1.0000 -5908502.5380 5908500.0685\n",
      "Ethnicity_2                   0.0592 2311552.7338   0.0000 1.0000 -4530560.0474 4530560.1658\n",
      "Races_0                      -1.9268 3633658.4313  -0.0000 1.0000 -7121841.5842 7121837.7306\n",
      "Races_1                      -1.2024 3418887.6680  -0.0000 1.0000 -6700897.8989 6700895.4941\n",
      "Races_2                      -0.5253 3134973.4449  -0.0000 1.0000 -6144435.5698 6144434.5191\n",
      "Races_3                       0.5206 2760664.8540   0.0000 1.0000 -5410803.1666 5410804.2079\n",
      "num_immunization             -0.2673       0.0118 -22.6231 0.0000       -0.2904      -0.2441\n",
      "Num med per admission mean    0.0596       0.0164   3.6208 0.0003        0.0273       0.0918\n",
      "Num med per admission min     0.0264       0.0075   3.5393 0.0004        0.0118       0.0410\n",
      "Num med per admission max     0.0303       0.0130   2.3375 0.0194        0.0049       0.0557\n",
      "Total medications            -0.0007       0.0001  -9.1092 0.0000       -0.0009      -0.0006\n",
      "mean age at specailty         0.6453       0.0286  22.5259 0.0000        0.5891       0.7014\n",
      "period mean                   0.0017       0.0036   0.4650 0.6419       -0.0053       0.0087\n",
      "period std                    0.0032       0.0018   1.7535 0.0795       -0.0004       0.0067\n",
      "specialty medical count       0.0273       0.0065   4.1859 0.0000        0.0145       0.0401\n",
      "specialty support count       0.0151       0.0065   2.3335 0.0196        0.0024       0.0278\n",
      "specialty count              -0.0107       0.0065  -1.6485 0.0992       -0.0233       0.0020\n",
      "Ruca category encoded        -0.0809       0.0233  -3.4760 0.0005       -0.1266      -0.0353\n",
      "Age 20-40 hypotension         0.0008       0.0048   0.1725 0.8631       -0.0085       0.0101\n",
      "Age 40-60 hypotension         0.0028       0.0006   4.6924 0.0000        0.0017       0.0040\n",
      "Age 60-80 hypotension         0.0012       0.0002   5.6237 0.0000        0.0008       0.0017\n",
      "Age 80-100 hypotension        0.0021       0.0004   5.9257 0.0000        0.0014       0.0028\n",
      "Age 100-120 hypotension       0.0004       0.0107   0.0369 0.9706       -0.0206       0.0214\n",
      "Age 20-40 hypertension       -0.0021       0.0029  -0.7327 0.4637       -0.0079       0.0036\n",
      "Age 40-60 hypertension       -0.0005       0.0002  -2.8161 0.0049       -0.0009      -0.0002\n",
      "Age 60-80 hypertension       -0.0004       0.0001  -3.8064 0.0001       -0.0006      -0.0002\n",
      "Age 80-100 hypertension      -0.0008       0.0002  -3.7665 0.0002       -0.0012      -0.0004\n",
      "Age 100-120 hypertension      0.0109       0.0076   1.4232 0.1547       -0.0041       0.0258\n",
      "Age 20-40 healthy            -0.0014       0.0035  -0.3858 0.6997       -0.0083       0.0055\n",
      "Age 40-60 healthy            -0.0015       0.0004  -3.3626 0.0008       -0.0024      -0.0006\n",
      "Age 60-80 healthy            -0.0003       0.0002  -1.3912 0.1642       -0.0006       0.0001\n",
      "Age 80-100 healthy           -0.0004       0.0003  -1.0381 0.2992       -0.0010       0.0003\n",
      "Age 100-120 healthy           0.0007       0.0072   0.0953 0.9241       -0.0134       0.0148\n",
      "lab_count                    -0.0002       0.0001  -2.6736 0.0075       -0.0003      -0.0000\n",
      "lab_freq                      0.0027       0.0004   7.2560 0.0000        0.0019       0.0034\n",
      "lab_age_mean                 -0.3125       0.0109 -28.7815 0.0000       -0.3337      -0.2912\n",
      "lab_age_std                  -0.4343       0.0149 -29.0546 0.0000       -0.4636      -0.4050\n",
      "============================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train_mor,X_train_mor)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"Linear Discriminant Analysis\":  LinearDiscriminantAnalysis(solver='lsqr')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Classifier has a training score of 82.0 % accuracy score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis Classifier has a training score of 83.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_mor, y_train_mor)\n",
    "    training_score = cross_val_score(classifier, X_train_mor, y_train_mor, cv=5)\n",
    "    print(classifier.__class__.__name__,\"Classifier has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from transformation import *    \n",
    "from grid_search_cv import *\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best = pickle.load(open('/home/daisy/FDA/models/LogisticRegression_readmission_2.sav','rb'))\n",
    "RF_best = pickle.load(open('/home/daisy/FDA/models/RandomForest_readmission_2.sav','rb'))\n",
    "DT_best = pickle.load(open('/home/daisy/FDA/models/DecisionTree_readmission_2.sav','rb'))\n",
    "XGB_best = pickle.load(open('/home/daisy/FDA/models/XGBoost_readmission_2.sav','rb'))\n",
    "LDA_best = pickle.load(open('/home/daisy/FDA/models/LinearDiscriminant_readmission_2.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {\n",
    "    'readmission': '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv', \n",
    "    'readmission_cvd': '/home/daisy/FDA_Dataset/inpatient_CVD_final_1.csv',\n",
    "    \"mortality\": '/home/daisy/FDA_Dataset/final_allcause_mortality_train_1.csv',\n",
    "    \"mortality_cvd\": '/home/daisy/FDA_Dataset/final_cvd_mortality_train_1.csv'\n",
    "}\n",
    "\n",
    "def prepare_dataset(target):\n",
    "    # Import Data\n",
    "    path =  dict_data[target]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "   \n",
    "    data_X = data[['Age 100-120 hypertension',\n",
    " 'Age 20-40 healthy',\n",
    " 'Age 40-60',\n",
    " 'Age 40-60 healthy',\n",
    " 'Age 40-60 hypertension',\n",
    " 'Age 60-80 healthy',\n",
    " 'Age 60-80 hypertension',\n",
    " 'Age 60-80 hypotension',\n",
    " 'Age 80-100 healthy',\n",
    " 'Age 80-100 hypertension',\n",
    " 'Age 80-100 hypotension',\n",
    " 'CVD',\n",
    " 'DOMICILIARY',\n",
    " 'Ethnicity_0',\n",
    " 'Height',\n",
    " 'MEDICINE',\n",
    " 'Num med per admission mean',\n",
    " 'Others_Specialty',\n",
    " 'Pulse oximetry max',\n",
    " 'Pulse oximetry mean',\n",
    " 'Pulse oximetry min',\n",
    " 'Pulse oximetry std',\n",
    " 'Races_0',\n",
    " 'Races_2',\n",
    " 'SURGERY',\n",
    " 'Total medications',\n",
    " 'Weight',\n",
    " 'age_std',\n",
    " 'lab_age_mean',\n",
    " 'lab_age_std',\n",
    " 'lab_count',\n",
    " 'lab_freq',\n",
    " 'mean age at specailty',\n",
    " 'num_stays',\n",
    " 'period mean',\n",
    " 'period std',\n",
    " 'specialty count',\n",
    " 'specialty medical count',\n",
    " 'specialty support count',\n",
    " 'stay_length',\n",
    " 'stay_max',\n",
    " 'stay_mean',\n",
    " 'stay_min',\n",
    " 'stay_std',\n",
    " 'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1', 'Races_3', 'Ruca category encoded']]\n",
    "    if target == \"readmission\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data_X\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    else:\n",
    "        X = data.drop(columns = ['Internalpatientid','died_by_cvd','Age at death'])\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "        \n",
    "\n",
    "    # # Split Train and Test (?? 似乎不用)\n",
    "    # X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 = train_test_split(X_admission1, Y_admission1, test_size=0.20, random_state=42)\n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis()),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "    X = transform_pipeline.transform(X)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "\n",
    "    # Balance the dataset\n",
    "    sme = SMOTEENN(random_state=42)\n",
    "    X, y = sme.fit_resample(X, y)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daisy/FDA/src/models/transformation.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname].fillna((X[colname].mean()), inplace = True)\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i] = self.scalar.fit_transform(X[i].values.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [40819 43717]\n",
      "[0 1] [14552 11950]\n"
     ]
    }
   ],
   "source": [
    "X,y = prepare_dataset(\"readmission\")\n",
    "eclf1 = VotingClassifier(estimators=[('rf', RF_best),('lr', LR_best),\n",
    "        ('dt', DT_best)], voting='hard',weights=[2,1,1], n_jobs=3)\n",
    "eclf1 = eclf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('rf', RF_best),('lr', LR_best),\n",
    "        ('dt', DT_best)], voting='hard',weights=[2,1,1], n_jobs=3)\n",
    "eclf2 = eclf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(401)\n",
    "\n",
    "\n",
    "def get_AUPRC(y_test, y_pred):\n",
    "    average_precision_score(y_test, y_pred)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n",
    "\n",
    "def get_AUROC(y_test, y_pred):\n",
    "    auc_roc_score = roc_auc_score(y_test, y_pred)\n",
    "    return auc_roc_score\n",
    "\n",
    "def get_Accurarcy(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def get_SensitSpecific(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "\n",
    "    #As it was mentioned in the other answers, specificity is the recall of the negative class\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0) # TN / (TN + FP) \n",
    "    return sensitivity + specificity\n",
    "\n",
    "def get_Sensitivity(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "    return sensitivity\n",
    "\n",
    "def get_Specificity(y_test, y_pred):\n",
    "    specificity = recall_score(y_test, y_pred, average = 'binary', pos_label=0) # TN / (TN + FP) \n",
    "    return specificity\n",
    "\n",
    "def get_Precision(y_test, y_pred):\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    return precision\n",
    "\n",
    "def get_F1score(y_test, y_pred):\n",
    "    score = f1_score(y_test, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "def get_NPC(y_test, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    npc =  tn / (tn + fn)\n",
    "    return npc\n",
    "\n",
    "def get_PositiveLR(y_test, y_pred):\n",
    "    # sensitivity / (1 - specificity)\n",
    "    positive_lr = get_Sensitivity(y_test, y_pred) / (1 - get_Specificity(y_test, y_pred))\n",
    "    return positive_lr\n",
    "\n",
    "def get_NegativeLR(y_test, y_pred):\n",
    "    # (1 - sensitivity) / specificity\n",
    "    negative_lr = (1 - get_Sensitivity(y_test, y_pred)) / get_Specificity(y_test, y_pred)\n",
    "    return negative_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_target_info = {\n",
    "    'mortality': ['/home/daisy/FDA_Dataset/final_allcause_mortality_test_1.csv','/home/vivi/FDA/models/RandomForest_mortality.sav'],\n",
    "    'mortality_cvd':['/home/daisy/FDA_Dataset/final_cvd_mortality_test_1.csv', '/home/vivi/FDA/models/RandomForest_mortality_cvd.sav'],\n",
    "    'readmission': ['/home/daisy/FDA_Dataset/inpatient_all_final_test_1.csv', \"/home/vivi/FDA/models/LinearDiscriminant_readmission.sav\"],\n",
    "    'readmission_cvd': ['/home/daisy/FDA_Dataset/inpatient_CVD_final_test_1.csv', '/home/vivi/FDA/models/DecisionTree_readmission_cvd.sav']\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_dataset(target,feature_names):\n",
    "    # Import Data\n",
    "    path =  dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    \n",
    "    data_X = data[['Age 100-120 hypertension',\n",
    " 'Age 20-40 healthy',\n",
    " 'Age 40-60',\n",
    " 'Age 40-60 healthy',\n",
    " 'Age 40-60 hypertension',\n",
    " 'Age 60-80 healthy',\n",
    " 'Age 60-80 hypertension',\n",
    " 'Age 60-80 hypotension',\n",
    " 'Age 80-100 healthy',\n",
    " 'Age 80-100 hypertension',\n",
    " 'Age 80-100 hypotension',\n",
    " 'CVD',\n",
    " 'DOMICILIARY',\n",
    " 'Ethnicity_0',\n",
    " 'Height',\n",
    " 'MEDICINE',\n",
    " 'Num med per admission mean',\n",
    " 'Others_Specialty',\n",
    " 'Pulse oximetry max',\n",
    " 'Pulse oximetry mean',\n",
    " 'Pulse oximetry min',\n",
    " 'Pulse oximetry std',\n",
    " 'Races_0',\n",
    " 'Races_2',\n",
    " 'SURGERY',\n",
    " 'Total medications',\n",
    " 'Weight',\n",
    " 'age_std',\n",
    " 'lab_age_mean',\n",
    " 'lab_age_std',\n",
    " 'lab_count',\n",
    " 'lab_freq',\n",
    " 'mean age at specailty',\n",
    " 'num_stays',\n",
    " 'period mean',\n",
    " 'period std',\n",
    " 'specialty count',\n",
    " 'specialty medical count',\n",
    " 'specialty support count',\n",
    " 'stay_length',\n",
    " 'stay_max',\n",
    " 'stay_mean',\n",
    " 'stay_min',\n",
    " 'stay_std',\n",
    " 'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1', 'Races_3', 'Ruca category encoded']]\n",
    "    if target == \"readmission\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data_X\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    else:\n",
    "        print(target)\n",
    "        X = data.drop(columns = ['Internalpatientid','died_by_cvd','Age at death'])\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "    \n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis(feature_names)),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "    X = transform_pipeline.transform(X)\n",
    "\n",
    "    X = X[feature_names]\n",
    "    return X,y\n",
    "\n",
    "def get_patientId(target):\n",
    "    path = dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    patientId = pd.DataFrame(data['Internalpatientid'])\n",
    "    return patientId\n",
    "\n",
    "def make_prediction(X,target,clf):\n",
    "    predict_label = clf.predict(X)\n",
    "    #predict_contin = [pair[1] for pair in clf.predict_proba(X)] #for soft\n",
    "    # return predict_label, predict_contin #for soft\n",
    "    return predict_label\n",
    "\n",
    "def calculate_score(y, predict_label):\n",
    "    scores = [\n",
    "        get_AUPRC(y, predict_label),\n",
    "        get_AUROC(y, predict_label),\n",
    "        get_Accurarcy(y, predict_label),\n",
    "        get_SensitSpecific(y, predict_label),\n",
    "        get_Sensitivity(y, predict_label),\n",
    "        get_Specificity(y, predict_label),\n",
    "        get_Precision(y, predict_label),\n",
    "        get_NPC(y, predict_label),\n",
    "        get_PositiveLR(y, predict_label),\n",
    "        get_NegativeLR(y, predict_label),\n",
    "        get_F1score(y, predict_label)\n",
    "    ]\n",
    "    return scores\n",
    "\n",
    "def make_df():\n",
    "    statistics_metrics1 = pd.DataFrame(['Area under the precision recall curve (AUPRC)',\n",
    "                                       'Area under the Receiver Operating Characteristic (AUROC)',\n",
    "                                       'Overall Accuracy',\n",
    "                                       'Sum of Sensitivity and Specificity',\n",
    "                                       'Sensitivity',\n",
    "                                       'Specificity',\n",
    "                                       'Precision',\n",
    "                                       'Negative Predictive Value',\n",
    "                                       'Positive Likelihood Ratio',\n",
    "                                       'Negative Likelihood Ratio',\n",
    "                                       'F1 score'], columns=['statistics_metrics'])\n",
    "    target = 'readmission'\n",
    "    X_test1, y_test1= prepare_dataset(target, eclf1.feature_names_in_)\n",
    "    # predict_label, predict_contin = make_prediction(X,target,eclf1) # for soft\n",
    "    predict_label = make_prediction(X_test1,target,eclf1)\n",
    "    scores1 = calculate_score(y_test1, predict_label)\n",
    "    statistics_metrics1[target] = scores1\n",
    "    return statistics_metrics1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daisy/FDA/src/models/transformation.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname].fillna((X[colname].mean()), inplace = True)\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname+'_log'] = np.log1p(X[colname])\n",
      "/home/daisy/FDA/src/models/transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i] = self.scalar.fit_transform(X[i].values.reshape(-1,1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistics_metrics</th>\n",
       "      <th>readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area under the precision recall curve (AUPRC)</td>\n",
       "      <td>0.794082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area under the Receiver Operating Characterist...</td>\n",
       "      <td>0.715626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overall Accuracy</td>\n",
       "      <td>0.715614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sum of Sensitivity and Specificity</td>\n",
       "      <td>1.431252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.715198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.716054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.726707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative Predictive Value</td>\n",
       "      <td>0.704279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive Likelihood Ratio</td>\n",
       "      <td>2.518782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative Likelihood Ratio</td>\n",
       "      <td>0.397738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.720907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   statistics_metrics  readmission\n",
       "0       Area under the precision recall curve (AUPRC)     0.794082\n",
       "1   Area under the Receiver Operating Characterist...     0.715626\n",
       "2                                    Overall Accuracy     0.715614\n",
       "3                  Sum of Sensitivity and Specificity     1.431252\n",
       "4                                         Sensitivity     0.715198\n",
       "5                                         Specificity     0.716054\n",
       "6                                           Precision     0.726707\n",
       "7                           Negative Predictive Value     0.704279\n",
       "8                           Positive Likelihood Ratio     2.518782\n",
       "9                           Negative Likelihood Ratio     0.397738\n",
       "10                                           F1 score     0.720907"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_df()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
