{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from transformation import *    \n",
    "from grid_search_cv import *\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best = pickle.load(open('/home/daisy/FDA/models/LogisticRegression_readmission_2.sav','rb'))\n",
    "RF_best = pickle.load(open('/home/daisy/FDA/models/RandomForest_readmission_2.sav','rb'))\n",
    "DT_best = pickle.load(open('/home/daisy/FDA/models/DecisionTree_readmission_2.sav','rb'))\n",
    "XGB_best = pickle.load(open('/home/daisy/FDA/models/XGBoost_readmission_2.sav','rb'))\n",
    "LDA_best = pickle.load(open('/home/daisy/FDA/models/LinearDiscriminant_readmission_2.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age 100-120 hypertension</th>\n",
       "      <th>Age 20-40 healthy</th>\n",
       "      <th>Age 40-60</th>\n",
       "      <th>Age 40-60 healthy</th>\n",
       "      <th>Age 40-60 hypertension</th>\n",
       "      <th>Age 60-80 healthy</th>\n",
       "      <th>Age 60-80 hypertension</th>\n",
       "      <th>Age 60-80 hypotension</th>\n",
       "      <th>Age 80-100 healthy</th>\n",
       "      <th>Age 80-100 hypertension</th>\n",
       "      <th>...</th>\n",
       "      <th>stay_std</th>\n",
       "      <th>total_procedure</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Races</th>\n",
       "      <th>Ethnicity_1</th>\n",
       "      <th>Ethnicity_2</th>\n",
       "      <th>Races_1</th>\n",
       "      <th>Races_3</th>\n",
       "      <th>Ruca category encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.334616</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.944396</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.449977</td>\n",
       "      <td>858.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.956604</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.439535</td>\n",
       "      <td>8609.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.181980</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61683</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.903264</td>\n",
       "      <td>424.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61684 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age 100-120 hypertension  Age 20-40 healthy  Age 40-60  \\\n",
       "0                           0.0                0.0          0   \n",
       "1                           NaN                NaN          0   \n",
       "2                           0.0                0.0          0   \n",
       "3                           0.0                0.0          4   \n",
       "4                           0.0                0.0          0   \n",
       "...                         ...                ...        ...   \n",
       "61679                       0.0                0.0          1   \n",
       "61680                       0.0                0.0          0   \n",
       "61681                       0.0                0.0          0   \n",
       "61682                       0.0                0.0          3   \n",
       "61683                       0.0                0.0          0   \n",
       "\n",
       "       Age 40-60 healthy  Age 40-60 hypertension  Age 60-80 healthy  \\\n",
       "0                    0.0                     4.0               34.0   \n",
       "1                    NaN                     NaN                NaN   \n",
       "2                    0.0                     0.0                4.0   \n",
       "3                   49.0                    20.0               58.0   \n",
       "4                    0.0                     0.0               16.0   \n",
       "...                  ...                     ...                ...   \n",
       "61679               15.0                    51.0                0.0   \n",
       "61680                0.0                     0.0              115.0   \n",
       "61681                0.0                     0.0              109.0   \n",
       "61682                4.0                    43.0               57.0   \n",
       "61683                0.0                     0.0               41.0   \n",
       "\n",
       "       Age 60-80 hypertension  Age 60-80 hypotension  Age 80-100 healthy  \\\n",
       "0                       134.0                    6.0                 0.0   \n",
       "1                         NaN                    NaN                 NaN   \n",
       "2                        16.0                   10.0                 0.0   \n",
       "3                        23.0                   20.0                 0.0   \n",
       "4                       111.0                    5.0                 0.0   \n",
       "...                       ...                    ...                 ...   \n",
       "61679                     0.0                    0.0                 0.0   \n",
       "61680                    67.0                   87.0               114.0   \n",
       "61681                   247.0                   37.0               221.0   \n",
       "61682                    42.0                   30.0                 0.0   \n",
       "61683                    44.0                   14.0                 0.0   \n",
       "\n",
       "       Age 80-100 hypertension  ...   stay_std  total_procedure  Ethnicity  \\\n",
       "0                          0.0  ...   1.334616            824.0          1   \n",
       "1                          NaN  ...   0.000000             60.0          2   \n",
       "2                          0.0  ...   0.000000            182.0          1   \n",
       "3                          0.0  ...  25.944396           1290.0          1   \n",
       "4                          0.0  ...   1.449977            858.0          1   \n",
       "...                        ...  ...        ...              ...        ...   \n",
       "61679                      0.0  ...   0.000000            245.0          1   \n",
       "61680                     64.0  ...  17.956604           1131.0          1   \n",
       "61681                    217.0  ...   3.439535           8609.0          1   \n",
       "61682                      0.0  ...   8.181980           1383.0          2   \n",
       "61683                      0.0  ...  14.903264            424.0          2   \n",
       "\n",
       "       Gender  Races  Ethnicity_1  Ethnicity_2  Races_1  Races_3  \\\n",
       "0           1      0            1            0        0        0   \n",
       "1           1      1            0            1        1        0   \n",
       "2           1      0            1            0        0        0   \n",
       "3           1      2            1            0        0        0   \n",
       "4           1      0            1            0        0        0   \n",
       "...       ...    ...          ...          ...      ...      ...   \n",
       "61679       1      2            1            0        0        0   \n",
       "61680       1      0            1            0        0        0   \n",
       "61681       1      2            1            0        0        0   \n",
       "61682       1      1            0            1        1        0   \n",
       "61683       1      0            0            1        0        0   \n",
       "\n",
       "       Ruca category encoded  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "...                      ...  \n",
       "61679                    0.0  \n",
       "61680                    0.0  \n",
       "61681                    0.0  \n",
       "61682                    1.0  \n",
       "61683                    0.0  \n",
       "\n",
       "[61684 rows x 53 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/daisy/FDA_Dataset/inpatient_CVD_final_1.csv'\n",
    "ad = pd.read_csv(path).iloc[:,1:]\n",
    "ad[['Age 100-120 hypertension',\n",
    " 'Age 20-40 healthy',\n",
    " 'Age 40-60',\n",
    " 'Age 40-60 healthy',\n",
    " 'Age 40-60 hypertension',\n",
    " 'Age 60-80 healthy',\n",
    " 'Age 60-80 hypertension',\n",
    " 'Age 60-80 hypotension',\n",
    " 'Age 80-100 healthy',\n",
    " 'Age 80-100 hypertension',\n",
    " 'Age 80-100 hypotension',\n",
    " 'CVD',\n",
    " 'DOMICILIARY',\n",
    " 'Ethnicity_0',\n",
    " 'Height',\n",
    " 'MEDICINE',\n",
    " 'Num med per admission mean',\n",
    " 'Others_Specialty',\n",
    " 'Pulse oximetry max',\n",
    " 'Pulse oximetry mean',\n",
    " 'Pulse oximetry min',\n",
    " 'Pulse oximetry std',\n",
    " 'Races_0',\n",
    " 'Races_2',\n",
    " 'SURGERY',\n",
    " 'Total medications',\n",
    " 'Weight',\n",
    " 'age_std',\n",
    " 'lab_age_mean',\n",
    " 'lab_age_std',\n",
    " 'lab_count',\n",
    " 'lab_freq',\n",
    " 'mean age at specailty',\n",
    " 'num_stays',\n",
    " 'period mean',\n",
    " 'period std',\n",
    " 'specialty count',\n",
    " 'specialty medical count',\n",
    " 'specialty support count',\n",
    " 'stay_length',\n",
    " 'stay_max',\n",
    " 'stay_mean',\n",
    " 'stay_min',\n",
    " 'stay_std',\n",
    " 'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1', 'Races_3', 'Ruca category encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {\n",
    "    'readmission': '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv', \n",
    "    'readmission_cvd': '/home/daisy/FDA_Dataset/inpatient_CVD_final_1.csv',\n",
    "    \"mortality\": '/home/daisy/FDA_Dataset/final_allcause_mortality_train_1.csv',\n",
    "    \"mortality_cvd\": '/home/daisy/FDA_Dataset/final_cvd_mortality_train_1.csv'\n",
    "}\n",
    "\n",
    "def prepare_train_dataset(target):\n",
    "    # Import Data\n",
    "    path =  dict_data[target]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    if \"readmission\" in target:\n",
    "        data_X_ad = data[['Age 100-120 hypertension',\n",
    "    'Age 20-40 healthy',\n",
    "    'Age 40-60',\n",
    "    'Age 40-60 healthy',\n",
    "    'Age 40-60 hypertension',\n",
    "    'Age 60-80 healthy',\n",
    "    'Age 60-80 hypertension',\n",
    "    'Age 60-80 hypotension',\n",
    "    'Age 80-100 healthy',\n",
    "    'Age 80-100 hypertension',\n",
    "    'Age 80-100 hypotension',\n",
    "    'CVD',\n",
    "    'DOMICILIARY',\n",
    "    'Ethnicity_0',\n",
    "    'Height',\n",
    "    'MEDICINE',\n",
    "    'Num med per admission mean',\n",
    "    'Others_Specialty',\n",
    "    'Pulse oximetry max',\n",
    "    'Pulse oximetry mean',\n",
    "    'Pulse oximetry min',\n",
    "    'Pulse oximetry std',\n",
    "    'Races_0',\n",
    "    'Races_2',\n",
    "    'SURGERY',\n",
    "    'Total medications',\n",
    "    'Weight',\n",
    "    'age_std',\n",
    "    'lab_age_mean',\n",
    "    'lab_age_std',\n",
    "    'lab_count',\n",
    "    'lab_freq',\n",
    "    'mean age at specailty',\n",
    "    'num_stays',\n",
    "    'period mean',\n",
    "    'period std',\n",
    "    'specialty count',\n",
    "    'specialty medical count',\n",
    "    'specialty support count',\n",
    "    'stay_length',\n",
    "    'stay_max',\n",
    "    'stay_mean',\n",
    "    'stay_min',\n",
    "    'stay_std',\n",
    "    'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1', 'Races_3', 'Ruca category encoded']]\n",
    "\n",
    "    if 'mortality' in target:\n",
    "        data_X_mor =  data[['Age 00-20',\n",
    "    'Age 100-120 hypertension',\n",
    "    'Age 20-40',\n",
    "    'Age 20-40 healthy',\n",
    "    'Age 20-40 hypertension',\n",
    "    'Age 40-60',\n",
    "    'Age 40-60 healthy',\n",
    "    'Age 40-60 hypertension',\n",
    "    'Age 60-80',\n",
    "    'Age 60-80 hypotension',\n",
    "    'Age 80-100',\n",
    "    'Age 80-100 healthy',\n",
    "    'Age 80-100 hypertension',\n",
    "    'Age 80-100 hypotension',\n",
    "    'CVD',\n",
    "    'Ethnicity_0',\n",
    "    'Ethnicity_2',\n",
    "    'Gender',\n",
    "    'Height',\n",
    "    'Pulse oximetry max',\n",
    "    'Pulse oximetry mean',\n",
    "    'Pulse oximetry min',\n",
    "    'Pulse oximetry std',\n",
    "    'Races_0',\n",
    "    'Races_3',\n",
    "    'Ruca category encoded',\n",
    "    'Total medications',\n",
    "    'Weight',\n",
    "    'age_mean',\n",
    "    'age_std',\n",
    "    'freq',\n",
    "    'lab_age_mean',\n",
    "    'lab_age_std',\n",
    "    'lab_count',\n",
    "    'lab_freq',\n",
    "    'mean age at specailty',\n",
    "    'num_immunization',\n",
    "    'num_surgery_pro',\n",
    "    'num_visits',\n",
    "    'period mean',\n",
    "    'period std',\n",
    "    'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1', 'Races_3', 'Ruca category encoded']]\n",
    "\n",
    "\n",
    "    if target == \"readmission\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data_X_ad\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        # X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data_X_ad\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        X = data_X_mor\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    else:\n",
    "        #X = data.drop(columns = ['Internalpatientid','died_by_cvd','Age at death'])\n",
    "        X = data_X_mor\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "        \n",
    "\n",
    "    # # Split Train and Test (?? 似乎不用)\n",
    "    # X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 = train_test_split(X_admission1, Y_admission1, test_size=0.20, random_state=42)\n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis()),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "    X = transform_pipeline.transform(X)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "\n",
    "    # Balance the dataset\n",
    "    sme = SMOTEENN(random_state=42)\n",
    "    X, y = sme.fit_resample(X, y)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(401)\n",
    "\n",
    "\n",
    "def get_AUPRC(y_test, y_pred):\n",
    "    average_precision_score(y_test, y_pred)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n",
    "\n",
    "def get_AUROC(y_test, y_pred):\n",
    "    auc_roc_score = roc_auc_score(y_test, y_pred)\n",
    "    return auc_roc_score\n",
    "\n",
    "def get_Accurarcy(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def get_SensitSpecific(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "\n",
    "    #As it was mentioned in the other answers, specificity is the recall of the negative class\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0) # TN / (TN + FP) \n",
    "    return sensitivity + specificity\n",
    "\n",
    "def get_Sensitivity(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "    return sensitivity\n",
    "\n",
    "def get_Specificity(y_test, y_pred):\n",
    "    specificity = recall_score(y_test, y_pred, average = 'binary', pos_label=0) # TN / (TN + FP) \n",
    "    return specificity\n",
    "\n",
    "def get_Precision(y_test, y_pred):\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    return precision\n",
    "\n",
    "def get_F1score(y_test, y_pred):\n",
    "    score = f1_score(y_test, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "def get_NPC(y_test, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    npc =  tn / (tn + fn)\n",
    "    return npc\n",
    "\n",
    "def get_PositiveLR(y_test, y_pred):\n",
    "    # sensitivity / (1 - specificity)\n",
    "    positive_lr = get_Sensitivity(y_test, y_pred) / (1 - get_Specificity(y_test, y_pred))\n",
    "    return positive_lr\n",
    "\n",
    "def get_NegativeLR(y_test, y_pred):\n",
    "    # (1 - sensitivity) / specificity\n",
    "    negative_lr = (1 - get_Sensitivity(y_test, y_pred)) / get_Specificity(y_test, y_pred)\n",
    "    return negative_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_target_info = {\n",
    "    'mortality': ['/home/daisy/FDA_Dataset/final_allcause_mortality_test_1.csv','/home/vivi/FDA/models/RandomForest_mortality.sav'],\n",
    "    'mortality_cvd':['/home/daisy/FDA_Dataset/final_cvd_mortality_test_1.csv', '/home/vivi/FDA/models/RandomForest_mortality_cvd.sav'],\n",
    "    'readmission': ['/home/daisy/FDA_Dataset/inpatient_all_final_test_1.csv', \"/home/vivi/FDA/models/LinearDiscriminant_readmission.sav\"],\n",
    "    'readmission_cvd': ['/home/daisy/FDA_Dataset/inpatient_CVD_final_test_1.csv', '/home/vivi/FDA/models/DecisionTree_readmission_cvd.sav']\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_test_dataset(target,feature_names):\n",
    "    # Import Data\n",
    "    path =  dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "\n",
    "    if target == \"readmission\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    else:\n",
    "        X = data.drop(columns = ['Internalpatientid','died_by_cvd','Age at death'])\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "    \n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis(feature_names)),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "    X = transform_pipeline.transform(X)\n",
    "\n",
    "    X = X[feature_names]\n",
    "    return X,y\n",
    "\n",
    "def get_patientId(target):\n",
    "    path = dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    patientId = pd.DataFrame(data['Internalpatientid'])\n",
    "    return patientId\n",
    "\n",
    "def make_prediction(X,target,clf):\n",
    "    predict_label = clf.predict(X)\n",
    "    #predict_contin = [pair[1] for pair in clf.predict_proba(X)] #for soft\n",
    "    # return predict_label, predict_contin #for soft\n",
    "    return predict_label\n",
    "\n",
    "def calculate_score(y, predict_label):\n",
    "    scores = [\n",
    "        get_AUPRC(y, predict_label),\n",
    "        get_AUROC(y, predict_label),\n",
    "        get_Accurarcy(y, predict_label),\n",
    "        get_SensitSpecific(y, predict_label),\n",
    "        get_Sensitivity(y, predict_label),\n",
    "        get_Specificity(y, predict_label),\n",
    "        get_Precision(y, predict_label),\n",
    "        get_NPC(y, predict_label),\n",
    "        get_PositiveLR(y, predict_label),\n",
    "        get_NegativeLR(y, predict_label),\n",
    "        get_F1score(y, predict_label)\n",
    "    ]\n",
    "    return scores\n",
    "\n",
    "def make_df(target, clf):\n",
    "    statistics_metrics = pd.DataFrame(['Area under the precision recall curve (AUPRC)',\n",
    "                                       'Area under the Receiver Operating Characteristic (AUROC)',\n",
    "                                       'Overall Accuracy',\n",
    "                                       'Sum of Sensitivity and Specificity',\n",
    "                                       'Sensitivity',\n",
    "                                       'Specificity',\n",
    "                                       'Precision',\n",
    "                                       'Negative Predictive Value',\n",
    "                                       'Positive Likelihood Ratio',\n",
    "                                       'Negative Likelihood Ratio',\n",
    "                                       'F1 score'], columns=['statistics_metrics'])\n",
    "    X_test, y_test= prepare_test_dataset(target, clf.feature_names_in_)\n",
    "    # predict_label, predict_contin = make_prediction(X,target,eclf1) # for soft\n",
    "    predict_label = make_prediction(X_test,target,clf)\n",
    "    scores = calculate_score(y_test, predict_label)\n",
    "    statistics_metrics[target] = scores\n",
    "    print(statistics_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daisy/FDA/src/models/transformation.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[colname].fillna((X[colname].mean()), inplace = True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_402193/2351516725.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mortality\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"readmission\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"readmission_cvd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     eclf1 = VotingClassifier(estimators=[('rf', RF_best),('lr', LR_best),\n\u001b[1;32m      6\u001b[0m         ('dt', DT_best)], voting='hard',weights=[2,1,1], n_jobs=3)\n\u001b[1;32m      7\u001b[0m     \u001b[0meclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_402193/3332228870.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'RemoveSkewnessKurtosis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemoveSkewnessKurtosis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n\u001b[1;32m    128\u001b[0m     \u001b[0mtransform_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \"\"\"\n\u001b[1;32m    656\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             return (\n",
      "\u001b[0;32m~/FDA/src/models/transformation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mmissing_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m          \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m          \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "targets = [\"mortality\", \"readmission\", \"readmission_cvd\"]\n",
    "\n",
    "for target in targets:\n",
    "    X_train,y_train = prepare_train_dataset(target)\n",
    "    eclf1 = VotingClassifier(estimators=[('rf', RF_best),('lr', LR_best),\n",
    "        ('dt', DT_best)], voting='hard',weights=[2,1,1], n_jobs=3)\n",
    "    eclf1 = eclf1.fit(X_train, y_train)\n",
    "    statistics_metrics = make_df(target, eclf1)\n",
    "statistics_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
