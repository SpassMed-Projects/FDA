{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from transformation import *    \n",
    "from grid_search_cv import *\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best = pickle.load(open('/home/daisy/FDA/models/LogisticRegression_readmission_2.sav','rb'))\n",
    "RF_best = pickle.load(open('/home/daisy/FDA/models/RandomForest_readmission_2.sav','rb'))\n",
    "DT_best = pickle.load(open('/home/daisy/FDA/models/DecisionTree_readmission_2.sav','rb'))\n",
    "XGB_best = pickle.load(open('/home/daisy/FDA/models/XGBoost_readmission_2.sav','rb'))\n",
    "LDA_best = pickle.load(open('/home/daisy/FDA/models/LinearDiscriminant_readmission_2.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {\n",
    "    'readmission': '/home/daisy/FDA_Dataset/inpatient_all_final_1.csv', \n",
    "    'readmission_cvd': '/home/daisy/FDA_Dataset/inpatient_CVD_final_1.csv',\n",
    "    \"mortality\": '/home/daisy/FDA_Dataset/final_allcause_mortality_train_1.csv',\n",
    "    \"mortality_cvd\": '/home/daisy/FDA_Dataset/final_cvd_mortality_train_1.csv'\n",
    "}\n",
    "\n",
    "def prepare_train_dataset(target):\n",
    "    # Import Data\n",
    "    path =  dict_data[target]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    \n",
    "    readmission_features =['Age 100-120 hypertension',\n",
    "                        'Age 20-40 healthy',\n",
    "                        'Age 40-60',\n",
    "                        'Age 40-60 healthy',\n",
    "                        'Age 40-60 hypertension',\n",
    "                        'Age 60-80 healthy',\n",
    "                        'Age 60-80 hypertension',\n",
    "                        'Age 60-80 hypotension',\n",
    "                        'Age 80-100 healthy',\n",
    "                        'Age 80-100 hypertension',\n",
    "                        'Age 80-100 hypotension',\n",
    "                        'CVD',\n",
    "                        'DOMICILIARY',\n",
    "                        'Ethnicity_0',\n",
    "                        'Height',\n",
    "                        'MEDICINE',\n",
    "                        'Num med per admission mean',\n",
    "                        'Others_Specialty',\n",
    "                        'Pulse oximetry max',\n",
    "                        'Pulse oximetry mean',\n",
    "                        'Pulse oximetry min',\n",
    "                        'Pulse oximetry std',\n",
    "                        'Races_0',\n",
    "                        'Races_2',\n",
    "                        'SURGERY',\n",
    "                        'Total medications',\n",
    "                        'Weight',\n",
    "                        'age_std',\n",
    "                        'lab_age_mean',\n",
    "                        'lab_age_std',\n",
    "                        'lab_count',\n",
    "                        'lab_freq',\n",
    "                        'mean age at specailty',\n",
    "                        'num_stays',\n",
    "                        'period mean',\n",
    "                        'period std',\n",
    "                        'specialty count',\n",
    "                        'specialty medical count',\n",
    "                        'specialty support count',\n",
    "                        'stay_length',\n",
    "                        'stay_max',\n",
    "                        'stay_mean',\n",
    "                        'stay_min',\n",
    "                        'stay_std',\n",
    "                        'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1','Races_2', 'Races_3', 'Ruca category encoded']\n",
    "    mortality_features = ['Age 00-20',\n",
    "                'Age 100-120 hypertension',\n",
    "                'Age 20-40',\n",
    "                'Age 20-40 healthy',\n",
    "                'Age 20-40 hypertension',\n",
    "                'Age 40-60',\n",
    "                'Age 40-60 healthy',\n",
    "                'Age 40-60 hypertension',\n",
    "                'Age 60-80',\n",
    "                'Age 60-80 hypotension',\n",
    "                'Age 80-100',\n",
    "                'Age 80-100 healthy',\n",
    "                'Age 80-100 hypertension',\n",
    "                'Age 80-100 hypotension',\n",
    "                'CVD',\n",
    "                'Ethnicity_0',\n",
    "                'Ethnicity_2',\n",
    "                'Gender',\n",
    "                'Height',\n",
    "                'Pulse oximetry max',\n",
    "                'Pulse oximetry mean',\n",
    "                'Pulse oximetry min',\n",
    "                'Pulse oximetry std',\n",
    "                'Races_0',\n",
    "                'Races_3',\n",
    "                'Ruca category encoded',\n",
    "                'Total medications',\n",
    "                'Weight',\n",
    "                'age_mean',\n",
    "                'age_std',\n",
    "                'freq',\n",
    "                'lab_age_mean',\n",
    "                'lab_age_std',\n",
    "                'lab_count',\n",
    "                'lab_freq',\n",
    "                'mean age at specailty',\n",
    "                'num_immunization',\n",
    "                'num_surgery_pro',\n",
    "                'num_visits',\n",
    "                'period mean',\n",
    "                'period std',\n",
    "                'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1','Races_2', 'Races_3', 'Ruca category encoded']\n",
    "    mortality_cvd_features = ['Age 100-120 hypertension',\n",
    "            'Age 20-40 healthy',\n",
    "            'Age 20-40 hypertension',\n",
    "            'Age 40-60',\n",
    "            'Age 40-60 healthy',\n",
    "            'Age 40-60 hypertension',\n",
    "            'Age 40-60 hypotension',\n",
    "            'Age 60-80 healthy',\n",
    "            'Age 60-80 hypertension',\n",
    "            'CVD',\n",
    "            'DOMICILIARY',\n",
    "            'Ethnicity_0',\n",
    "            'Ethnicity_2',\n",
    "            'Height',\n",
    "            'Num med per admission mean',\n",
    "            'Others_Specialty',\n",
    "            'Pulse oximetry max',\n",
    "            'Pulse oximetry mean',\n",
    "            'Pulse oximetry std',\n",
    "            'Races',\n",
    "            'Races_0',\n",
    "            'SURGERY',\n",
    "            'Total medications',\n",
    "            'Weight',\n",
    "            'age_min',\n",
    "            'age_std',\n",
    "            'lab_age_mean',\n",
    "            'lab_age_std',\n",
    "            'lab_count',\n",
    "            'lab_freq',\n",
    "            'num_cvd_admission',\n",
    "            'period mean',\n",
    "            'period std',\n",
    "            'specialty count',\n",
    "            'stay_length',\n",
    "            'stay_max',\n",
    "            'stay_mean',\n",
    "            'stay_min',\n",
    "            'stay_std',\n",
    "            'total_procedure','Ethnicity', 'Gender', 'Races', 'Ethnicity_1', 'Ethnicity_2', 'Races_1','Races_2', 'Races_3', 'Ruca category encoded']\n",
    "\n",
    "    if target == \"readmission\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data[readmission_features]\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        # X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        X = data[readmission_features]\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        #X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        drops = set(data.columns).difference(set(mortality_features))\n",
    "        X = data.drop(columns = drops)\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    elif target == 'mortality_cvd':\n",
    "        drops = set(data.columns).difference(set(mortality_cvd_features))\n",
    "        X = data.drop(columns = drops)\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "        \n",
    "\n",
    "    # # Split Train and Test (?? 似乎不用)\n",
    "    # X_train_ad1, X_test_ad1, y_train_ad1, y_test_ad1 = train_test_split(X_admission1, Y_admission1, test_size=0.20, random_state=42)\n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis()),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "    X = transform_pipeline.transform(X)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    X.fillna(0,inplace=True)\n",
    "\n",
    "    # Balance the dataset\n",
    "    sme = SMOTEENN(random_state=42)\n",
    "    X, y = sme.fit_resample(X, y)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(401)\n",
    "\n",
    "\n",
    "def get_AUPRC(y_test, y_pred):\n",
    "    average_precision_score(y_test, y_pred)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n",
    "\n",
    "def get_AUROC(y_test, y_pred):\n",
    "    auc_roc_score = roc_auc_score(y_test, y_pred)\n",
    "    return auc_roc_score\n",
    "\n",
    "def get_Accurarcy(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def get_SensitSpecific(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "\n",
    "    #As it was mentioned in the other answers, specificity is the recall of the negative class\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0) # TN / (TN + FP) \n",
    "    return sensitivity + specificity\n",
    "\n",
    "def get_Sensitivity(y_test, y_pred):\n",
    "    sensitivity = recall_score(y_test, y_pred,average = 'binary') #TP / (TP + FN)\n",
    "    return sensitivity\n",
    "\n",
    "def get_Specificity(y_test, y_pred):\n",
    "    specificity = recall_score(y_test, y_pred, average = 'binary', pos_label=0) # TN / (TN + FP) \n",
    "    return specificity\n",
    "\n",
    "def get_Precision(y_test, y_pred):\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    return precision\n",
    "\n",
    "def get_F1score(y_test, y_pred):\n",
    "    score = f1_score(y_test, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "def get_NPC(y_test, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    npc =  tn / (tn + fn)\n",
    "    return npc\n",
    "\n",
    "def get_PositiveLR(y_test, y_pred):\n",
    "    # sensitivity / (1 - specificity)\n",
    "    positive_lr = get_Sensitivity(y_test, y_pred) / (1 - get_Specificity(y_test, y_pred))\n",
    "    return positive_lr\n",
    "\n",
    "def get_NegativeLR(y_test, y_pred):\n",
    "    # (1 - sensitivity) / specificity\n",
    "    negative_lr = (1 - get_Sensitivity(y_test, y_pred)) / get_Specificity(y_test, y_pred)\n",
    "    return negative_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_target_info = {\n",
    "    'mortality': ['/home/daisy/FDA_Dataset/final_allcause_mortality_test_1.csv','/home/vivi/FDA/models/RandomForest_mortality.sav'],\n",
    "    'mortality_cvd':['/home/daisy/FDA_Dataset/final_cvd_mortality_test_1.csv', '/home/vivi/FDA/models/RandomForest_mortality_cvd.sav'],\n",
    "    'readmission': ['/home/daisy/FDA_Dataset/inpatient_all_final_test_1.csv', \"/home/vivi/FDA/models/LinearDiscriminant_readmission.sav\"],\n",
    "    'readmission_cvd': ['/home/daisy/FDA_Dataset/inpatient_CVD_final_test_1.csv', '/home/vivi/FDA/models/DecisionTree_readmission_cvd.sav']\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_test_dataset(target,feature_names):\n",
    "    # Import Data\n",
    "    path =  dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "\n",
    "    if target == \"readmission\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['readmission within 300 days']])\n",
    "    elif target == \"readmission_cvd\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'CVD_readmission', 'readmission within 300 days'])\n",
    "        y = column_or_1d(data[['CVD_readmission']])\n",
    "    elif target == \"mortality\":\n",
    "        X = data.drop(columns = ['Internalpatientid', 'died_within_125days'])\n",
    "        y = column_or_1d(data[['died_within_125days']])\n",
    "    elif target == 'mortality_cvd':\n",
    "        X = data.drop(columns = ['Internalpatientid','died_by_cvd'])\n",
    "        y = column_or_1d(data[['died_by_cvd']])\n",
    "    \n",
    "    # Transform Data\n",
    "    transform_steps = [(\"ImputeNumeric\", ImputeNumeric()),\n",
    "                ('RemoveSkewnessKurtosis', RemoveSkewnessKurtosis(feature_names)),\n",
    "                ('StandardizeStandardScaler', Standardize(RobustScaler()))]\n",
    "    transform_pipeline = Pipeline(transform_steps)\n",
    "\n",
    "    X = transform_pipeline.transform(X)\n",
    "    \n",
    "    X = X[feature_names]\n",
    "    return X,y\n",
    "\n",
    "def get_patientId(target):\n",
    "    path = dict_target_info[target][0]\n",
    "    data = pd.read_csv(path).iloc[:,1:]\n",
    "    patientId = pd.DataFrame(data['Internalpatientid'])\n",
    "    return patientId\n",
    "\n",
    "def make_prediction(X,target,clf):\n",
    "    X.fillna(0,inplace=True)\n",
    "    predict_label = clf.predict(X)\n",
    "    predict_contin = [pair[1] for pair in clf.predict_proba(X)] #for soft\n",
    "    return predict_label, predict_contin \n",
    "\n",
    "def calculate_score(y, predict_label):\n",
    "    scores = [\n",
    "        get_AUPRC(y, predict_label),\n",
    "        get_AUROC(y, predict_label),\n",
    "        get_Accurarcy(y, predict_label),\n",
    "        get_SensitSpecific(y, predict_label),\n",
    "        get_Sensitivity(y, predict_label),\n",
    "        get_Specificity(y, predict_label),\n",
    "        get_Precision(y, predict_label),\n",
    "        get_NPC(y, predict_label),\n",
    "        get_PositiveLR(y, predict_label),\n",
    "        get_NegativeLR(y, predict_label),\n",
    "        get_F1score(y, predict_label)\n",
    "    ]\n",
    "    return scores\n",
    "\n",
    "def make_df(target, clf):\n",
    "    statistics_metrics = pd.DataFrame(['Area under the precision recall curve (AUPRC)',\n",
    "                                       'Area under the Receiver Operating Characteristic (AUROC)',\n",
    "                                       'Overall Accuracy',\n",
    "                                       'Sum of Sensitivity and Specificity',\n",
    "                                       'Sensitivity',\n",
    "                                       'Specificity',\n",
    "                                       'Precision',\n",
    "                                       'Negative Predictive Value',\n",
    "                                       'Positive Likelihood Ratio',\n",
    "                                       'Negative Likelihood Ratio',\n",
    "                                       'F1 score'], columns=['statistics_metrics'])\n",
    "    X_test, y_test= prepare_test_dataset(target, clf.feature_names_in_)\n",
    "    predict_label, predict_contin = make_prediction(X_test,target,clf) # for soft\n",
    "    #predict_label = make_prediction(X_test,target,clf)\n",
    "    scores = calculate_score(y_test, predict_label)\n",
    "    statistics_metrics[target] = scores\n",
    "    print(statistics_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/daisy/FDA/src/models/transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i] = self.scalar.fit_transform(X[i].values.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [59784  3758]\n",
      "[0 1] [36700 59538]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/hassan/.conda/envs/mla/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/daisy/FDA/src/models/transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i] = self.scalar.fit_transform(X[i].values.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   statistics_metrics  mortality_cvd\n",
      "0       Area under the precision recall curve (AUPRC)       0.467190\n",
      "1   Area under the Receiver Operating Characterist...       0.747324\n",
      "2                                    Overall Accuracy       0.721414\n",
      "3                  Sum of Sensitivity and Specificity       1.494648\n",
      "4                                         Sensitivity       0.776629\n",
      "5                                         Specificity       0.718019\n",
      "6                                           Precision       0.144813\n",
      "7                           Negative Predictive Value       0.981232\n",
      "8                           Positive Likelihood Ratio       2.754186\n",
      "9                           Negative Likelihood Ratio       0.311094\n",
      "10                                           F1 score       0.244109\n"
     ]
    }
   ],
   "source": [
    "targets =  [\"mortality_cvd\"]#[\"readmission\", \"readmission_cvd\", \"mortality\", \"mortality_cvd\"]\n",
    "\n",
    "for target in targets:\n",
    "    X_train,y_train = prepare_train_dataset(target)\n",
    "    eclf1 = VotingClassifier(estimators=[('rf', RF_best),('lr', LR_best),\n",
    "        ('dt', DT_best)], voting='soft', n_jobs=3)\n",
    "    eclf1 = eclf1.fit(X_train, y_train)\n",
    "    statistics_metrics = make_df(target, eclf1)\n",
    "statistics_metrics\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
